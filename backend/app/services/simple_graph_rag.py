# app/services/simple_graph_rag.py (ê°œì„ ëœ ë²„ì „)

from typing import Dict, List, Tuple, Set
from collections import defaultdict, Counter
from datetime import datetime
import json


class SimpleGraphRAG:
    """ê°„ë‹¨í•˜ê³  ì‹¤ìš©ì ì¸ Graph RAG ì‹œìŠ¤í…œ (Playwright ë°ì´í„° ê°•í™”)"""

    def __init__(self):
        # ë¯¸ë¦¬ ì •ì˜ëœ ì—”í‹°í‹° ê´€ê³„ ê·¸ë˜í”„ (í™•ì¥ë¨)
        self.entity_relations = {
            # ê¸°ì—… ê´€ê³„
            "ì‚¼ì„±ì „ì": ["SKí•˜ì´ë‹‰ìŠ¤", "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "AI", "TSMC"],
            "SKí•˜ì´ë‹‰ìŠ¤": ["ì‚¼ì„±ì „ì", "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "AI", "NVIDIA"],
            "LGí™”í•™": ["ë°°í„°ë¦¬", "ì „ê¸°ì°¨", "2ì°¨ì „ì§€", "í˜„ëŒ€ì°¨", "SKì´ë…¸ë² ì´ì…˜"],
            "í˜„ëŒ€ì°¨": ["ì „ê¸°ì°¨", "ìë™ì°¨", "ë°°í„°ë¦¬", "LGí™”í•™", "ê¸°ì•„"],
            "ë„¤ì´ë²„": ["IT", "í”Œë«í¼", "ì¹´ì¹´ì˜¤", "AI", "í´ë¼ìš°ë“œ"],
            "ì¹´ì¹´ì˜¤": ["IT", "í”Œë«í¼", "ë„¤ì´ë²„", "í•€í…Œí¬", "ê²Œì„"],
            # í•´ì™¸ ê¸°ì—…
            "NVIDIA": ["AI", "ë°˜ë„ì²´", "SKí•˜ì´ë‹‰ìŠ¤", "ë°ì´í„°ì„¼í„°", "GPU"],
            "TSMC": ["ë°˜ë„ì²´", "ì‚¼ì„±ì „ì", "AI", "íŒŒìš´ë“œë¦¬", "ì¹©"],
            # ì•”í˜¸í™”í ê´€ë ¨ (Playwrightë¡œ ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ ì—”í‹°í‹°ë“¤)
            "ë¹„íŠ¸ì½”ì¸": [
                "ì•”í˜¸í™”í",
                "ë¸”ë¡ì²´ì¸",
                "ìŠ¤í…Œì´ë¸”ì½”ì¸",
                "ë””ì§€í„¸ìì‚°",
                "í‡´ì§ì—°ê¸ˆ",
            ],
            "ìŠ¤í…Œì´ë¸”ì½”ì¸": ["ë¹„íŠ¸ì½”ì¸", "ì•”í˜¸í™”í", "ë¸”ë¡ì²´ì¸", "USDT", "USDC"],
            "ì•”í˜¸í™”í": ["ë¹„íŠ¸ì½”ì¸", "ìŠ¤í…Œì´ë¸”ì½”ì¸", "ë¸”ë¡ì²´ì¸", "ë¦¬í”Œ", "ì´ë”ë¦¬ì›€"],
            "ë¸”ë¡ì²´ì¸": ["ë¹„íŠ¸ì½”ì¸", "ì•”í˜¸í™”í", "ìŠ¤í…Œì´ë¸”ì½”ì¸", "NFT", "DeFi"],
            # AI ê´€ë ¨ (í™•ì¥ë¨)
            "AI": [
                "ë°˜ë„ì²´",
                "NVIDIA",
                "ë°ì´í„°ì„¼í„°",
                "í´ë¼ìš°ë“œ",
                "ë¹…í…Œí¬",
                "ì¸ê³µì§€ëŠ¥",
                "ë¨¸ì‹ ëŸ¬ë‹",
            ],
            "ì¸ê³µì§€ëŠ¥": ["AI", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ë°˜ë„ì²´", "ë°ì´í„°ì„¼í„°"],
            # ì„¹í„° ê´€ê³„ (í™•ì¥ë¨)
            "ë°˜ë„ì²´": ["AI", "ë©”ëª¨ë¦¬", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "TSMC", "NVIDIA"],
            "ì „ê¸°ì°¨": ["ë°°í„°ë¦¬", "ìë™ì°¨", "2ì°¨ì „ì§€", "í˜„ëŒ€ì°¨", "LGí™”í•™"],
            "ë°°í„°ë¦¬": ["ì „ê¸°ì°¨", "2ì°¨ì „ì§€", "LGí™”í•™", "SKì´ë…¸ë² ì´ì…˜", "ë¦¬íŠ¬"],
            "IT": ["AI", "í”Œë«í¼", "í´ë¼ìš°ë“œ", "ì†Œí”„íŠ¸ì›¨ì–´", "ë¹…í…Œí¬"],
            "ê¸ˆìœµ": ["ì€í–‰", "ë³´í—˜", "í•€í…Œí¬", "ê¸°ì¤€ê¸ˆë¦¬", "ê¸ˆë¦¬", "íˆ¬ì"],
            # ê²½ì œ ì§€í‘œ
            "ê¸°ì¤€ê¸ˆë¦¬": ["ê¸ˆìœµ", "ì€í–‰", "ë¶€ë™ì‚°", "ëŒ€ì¶œ", "í†µí™”ì •ì±…"],
            "í™˜ìœ¨": ["ìˆ˜ì¶œ", "ë¬´ì—­", "ë‹¬ëŸ¬", "ì›í™”", "ê²½ì œ"],
            "ì½”ìŠ¤í”¼": ["ì£¼ì‹", "ì¦ì‹œ", "ì™¸êµ­ì¸", "ê¸°ê´€", "ê°œì¸"],
        }

        # ì—”í‹°í‹° ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ (ì—…ë°ì´íŠ¸ë¨)
        self.entity_weights = {
            # ê¸°ì¡´ ê¸°ì—…ë“¤
            "ì‚¼ì„±ì „ì": 5,
            "SKí•˜ì´ë‹‰ìŠ¤": 4,
            "NVIDIA": 5,
            "TSMC": 4,
            "ë„¤ì´ë²„": 3,
            "ì¹´ì¹´ì˜¤": 3,
            "í˜„ëŒ€ì°¨": 3,
            "LGí™”í•™": 3,
            # ìƒˆë¡œ ì¶”ê°€ëœ ì•”í˜¸í™”í ê´€ë ¨
            "ë¹„íŠ¸ì½”ì¸": 5,
            "ìŠ¤í…Œì´ë¸”ì½”ì¸": 3,
            "ì•”í˜¸í™”í": 4,
            "ë¸”ë¡ì²´ì¸": 3,
            # AI ê´€ë ¨
            "AI": 5,
            "ì¸ê³µì§€ëŠ¥": 4,
            # ì„¹í„°
            "ë°˜ë„ì²´": 4,
            "ì „ê¸°ì°¨": 4,
            "ë°°í„°ë¦¬": 3,
            "IT": 3,
            # ê¸ˆìœµ ì§€í‘œ
            "ê¸°ì¤€ê¸ˆë¦¬": 5,
            "í™˜ìœ¨": 4,
            "ì½”ìŠ¤í”¼": 4,
            "ì¸í”Œë ˆì´ì…˜": 4,
        }

    def extract_entities_from_data(self, financial_data: Dict) -> List[str]:
        """ê¸ˆìœµ ë°ì´í„°ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (Playwright ë°ì´í„° ê°•í™”)"""
        entities = set()

        # ë‰´ìŠ¤ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (Playwrightë¡œ ìˆ˜ì§‘ëœ í’ë¶€í•œ ë°ì´í„°)
        for news in financial_data.get("news", []):
            # ê¸°ì¡´ ì—”í‹°í‹° ì¶”ê°€
            entities.update(news.entities)

            # ì œëª©ê³¼ ë³¸ë¬¸ì—ì„œ ì¶”ê°€ ì—”í‹°í‹° ì¶”ì¶œ (Playwright ì¥ì  í™œìš©)
            if hasattr(news, "summary") and news.summary:
                # ë³¸ë¬¸ ë‚´ìš©ì—ì„œ ì¶”ê°€ ì—”í‹°í‹° ì°¾ê¸°
                additional_entities = self._extract_entities_from_text(
                    news.title + " " + news.summary
                )
                entities.update(additional_entities)

        # ê³µì‹œì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ
        for disclosure in financial_data.get("disclosures", []):
            company = disclosure.company
            if company in self.entity_relations:
                entities.add(company)

            # ê³µì‹œ ì œëª©ì—ì„œ ì¶”ê°€ ì—”í‹°í‹° ì¶”ì¶œ
            title_entities = self._extract_entities_from_text(disclosure.title)
            entities.update(title_entities)

        # ì£¼ì‹ ë°ì´í„°ì—ì„œ ê¸°ì—…ëª… ì¶”ê°€
        for stock in financial_data.get("stock_data", []):
            if stock.company_name in self.entity_relations:
                entities.add(stock.company_name)

        return list(entities)

    def _extract_entities_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (Playwright ë³¸ë¬¸ í™œìš©)"""
        entities = set()

        # ëª¨ë“  ì•Œë ¤ì§„ ì—”í‹°í‹° ê²€ì‚¬
        for entity in self.entity_relations.keys():
            if entity in text:
                entities.add(entity)

        # ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ì—”í‹°í‹°ë„ ê²€ì‚¬
        for entity in self.entity_weights.keys():
            if entity in text:
                entities.add(entity)

        return entities

    def calculate_entity_importance(
        self, entities: List[str], news_data: List
    ) -> Dict[str, float]:
        """ì—”í‹°í‹° ì¤‘ìš”ë„ ê³„ì‚° (Playwright ë°ì´í„° ê°•í™”)"""
        importance_scores = {}

        # ë‰´ìŠ¤ ì–¸ê¸‰ ë¹ˆë„ ê³„ì‚° (ë³¸ë¬¸ ë‚´ìš© í¬í•¨)
        entity_mentions = Counter()
        content_mentions = Counter()  # ë³¸ë¬¸ì—ì„œì˜ ì–¸ê¸‰

        for news in news_data:
            # ì œëª©ì—ì„œì˜ ì–¸ê¸‰ (ê¸°ì¡´)
            for entity in news.entities:
                entity_mentions[entity] += 1

            # ë³¸ë¬¸ì—ì„œì˜ ì–¸ê¸‰ (Playwright ì¥ì )
            if hasattr(news, "summary") and news.summary:
                for entity in entities:
                    if entity in news.summary:
                        content_mentions[entity] += 1

        for entity in entities:
            # ê¸°ë³¸ ì¤‘ìš”ë„
            base_weight = self.entity_weights.get(entity, 1.0)

            # ì œëª© ì–¸ê¸‰ ë¹ˆë„ ë³´ë„ˆìŠ¤ (ë†’ì€ ê°€ì¤‘ì¹˜)
            title_bonus = entity_mentions.get(entity, 0) * 0.8

            # ë³¸ë¬¸ ì–¸ê¸‰ ë¹ˆë„ ë³´ë„ˆìŠ¤ (ì¤‘ê°„ ê°€ì¤‘ì¹˜)
            content_bonus = content_mentions.get(entity, 0) * 0.3

            # ê´€ê³„ ê°œìˆ˜ ë³´ë„ˆìŠ¤
            relation_count = len(self.entity_relations.get(entity, []))
            relation_bonus = min(relation_count * 0.1, 1.0)

            # ìµœì¢… ì¤‘ìš”ë„ ê³„ì‚°
            total_score = base_weight + title_bonus + content_bonus + relation_bonus
            importance_scores[entity] = round(total_score, 2)

        return importance_scores

    def analyze_entity_clusters(self, entities: List[str]) -> Dict[str, List[str]]:
        """ì—”í‹°í‹° í´ëŸ¬ìŠ¤í„° ë¶„ì„ (ì—…ë°ì´íŠ¸ëœ ì„¹í„°)"""
        clusters = defaultdict(list)

        # í™•ì¥ëœ ì„¹í„°ë³„ ë¶„ë¥˜
        sector_mapping = {
            "ë°˜ë„ì²´": ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "TSMC", "NVIDIA", "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬"],
            "ì „ê¸°ì°¨": ["í˜„ëŒ€ì°¨", "LGí™”í•™", "ë°°í„°ë¦¬", "2ì°¨ì „ì§€", "ì „ê¸°ì°¨"],
            "IT": ["ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "AI", "í”Œë«í¼", "ì¸ê³µì§€ëŠ¥", "í´ë¼ìš°ë“œ"],
            "ì•”í˜¸í™”í": [
                "ë¹„íŠ¸ì½”ì¸",
                "ìŠ¤í…Œì´ë¸”ì½”ì¸",
                "ì•”í˜¸í™”í",
                "ë¸”ë¡ì²´ì¸",
            ],  # ìƒˆë¡œ ì¶”ê°€
            "ê¸ˆìœµ": ["ê¸°ì¤€ê¸ˆë¦¬", "í™˜ìœ¨", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "íˆ¬ì", "ê¸ˆìœµ"],
            "ì—ë„ˆì§€": ["ìœ ê°€", "í™”í•™", "ì›ìì¬"],
        }

        for entity in entities:
            assigned = False
            for sector, sector_entities in sector_mapping.items():
                if entity in sector_entities:
                    clusters[sector].append(entity)
                    assigned = True
                    break

            if not assigned:
                clusters["ê¸°íƒ€"].append(entity)

        return dict(clusters)

    def create_market_narrative(self, financial_data: Dict) -> Dict:
        """ì‹œì¥ ë‚´ëŸ¬í‹°ë¸Œ ìƒì„± (Playwright ë°ì´í„° í™œìš©)"""
        entities = self.extract_entities_from_data(financial_data)

        print(f">>> Graph RAG: {len(entities)}ê°œ ì—”í‹°í‹° ì¶”ì¶œ")

        # ì—”í‹°í‹° ì¤‘ìš”ë„ ë¶„ì„ (ë³¸ë¬¸ ë°ì´í„° í™œìš©)
        importance_scores = self.calculate_entity_importance(
            entities, financial_data.get("news", [])
        )

        # í´ëŸ¬ìŠ¤í„° ë¶„ì„ (ì—…ë°ì´íŠ¸ëœ ì„¹í„°)
        clusters = self.analyze_entity_clusters(entities)

        # ì˜í–¥ ë¶„ì„
        impact_analysis = self.generate_impact_analysis(entities)

        # ìƒìœ„ ì—”í‹°í‹° ì„ ë³„
        top_entities = sorted(
            importance_scores.items(), key=lambda x: x[1], reverse=True
        )[:10]

        # í•µì‹¬ í…Œë§ˆ ì¶”ì¶œ (ì•”í˜¸í™”í í…Œë§ˆ ì¶”ê°€)
        main_themes = []
        for cluster_name, cluster_entities in clusters.items():
            if len(cluster_entities) >= 1:  # 1ê°œ ì´ìƒ ì—”í‹°í‹°ê°€ ìˆëŠ” í´ëŸ¬ìŠ¤í„°
                theme_importance = sum(
                    importance_scores.get(e, 0) for e in cluster_entities
                )
                main_themes.append(
                    {
                        "theme": cluster_name,
                        "entities": cluster_entities,
                        "importance": theme_importance,
                        "entity_count": len(cluster_entities),
                    }
                )

        main_themes.sort(key=lambda x: x["importance"], reverse=True)

        # ì‹œì¥ ë™í–¥ ìš”ì•½
        market_summary = {
            "total_entities": len(entities),
            "top_entities": top_entities[:8],
            "main_themes": main_themes[:5],  # ìƒìœ„ 5ê°œ í…Œë§ˆ
            "impact_chains": impact_analysis["impact_chains"][:3],
            "market_indices": financial_data.get("market", []),
            "news_coverage": {
                "total_news": len(financial_data.get("news", [])),
                "crypto_news": len(
                    [
                        n
                        for n in financial_data.get("news", [])
                        if any(
                            crypto in n.entities
                            for crypto in ["ë¹„íŠ¸ì½”ì¸", "ì•”í˜¸í™”í", "ìŠ¤í…Œì´ë¸”ì½”ì¸"]
                        )
                    ]
                ),
                "ai_news": len(
                    [
                        n
                        for n in financial_data.get("news", [])
                        if any(ai in n.entities for ai in ["AI", "ì¸ê³µì§€ëŠ¥"])
                    ]
                ),
            },
        }

        print(f">>> Graph RAG: ìƒìœ„ í…Œë§ˆ {len(main_themes)}ê°œ ìƒì„±")
        for theme in main_themes[:3]:
            print(
                f"  - {theme['theme']}: {theme['entity_count']}ê°œ ì—”í‹°í‹° (ì¤‘ìš”ë„: {theme['importance']:.1f})"
            )

        return {
            "entities": entities,
            "importance_scores": importance_scores,
            "clusters": clusters,
            "impact_analysis": impact_analysis,
            "market_summary": market_summary,
            "analysis_timestamp": datetime.now().isoformat(),
            "data_quality": {
                "has_content": any(
                    hasattr(n, "summary") and n.summary
                    for n in financial_data.get("news", [])
                ),
                "entity_coverage": len(entities)
                / max(len(financial_data.get("news", [])), 1),
            },
        }

    def generate_impact_analysis(self, entities: List[str]) -> Dict:
        """ì˜í–¥ ë¶„ì„ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        impact_chains = []

        for entity in entities:
            if entity in self.entity_relations:
                related = self.entity_relations[entity][:3]
                positive_impact = []
                negative_impact = []

                for related_entity in related:
                    if related_entity in entities:
                        # ê¸ì •ì /ë¶€ì •ì  ì˜í–¥ ë¶„ë¥˜ (ê°„ë‹¨í•œ ê·œì¹™)
                        if entity in ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"] and related_entity in [
                            "AI",
                            "ë°˜ë„ì²´",
                        ]:
                            positive_impact.append(related_entity)
                        elif entity == "ë¹„íŠ¸ì½”ì¸" and related_entity in [
                            "ì•”í˜¸í™”í",
                            "ë¸”ë¡ì²´ì¸",
                        ]:
                            positive_impact.append(related_entity)
                        elif entity == "ê¸°ì¤€ê¸ˆë¦¬" and related_entity == "ê¸ˆìœµ":
                            negative_impact.append(related_entity)
                        else:
                            positive_impact.append(related_entity)

                if positive_impact or negative_impact:
                    impact_chains.append(
                        {
                            "source": entity,
                            "positive_impact": positive_impact,
                            "negative_impact": negative_impact,
                        }
                    )

        return {
            "impact_chains": impact_chains,
            "total_entities": len(entities),
            "connected_entities": len(
                [e for e in entities if e in self.entity_relations]
            ),
        }

    def generate_insight_context(self, financial_data: Dict) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìƒì„±ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (Playwright ë°ì´í„° í™œìš©)"""
        narrative = self.create_market_narrative(financial_data)

        context = f"""
=== ê¸ˆìœµ ì‹œì¥ Graph RAG ë¶„ì„ ê²°ê³¼ (Playwright ê°•í™”) ===

ğŸ“Š ë°ì´í„° í’ˆì§ˆ:
- ì´ ë‰´ìŠ¤: {narrative['market_summary']['news_coverage']['total_news']}ê±´
- ì•”í˜¸í™”í ë‰´ìŠ¤: {narrative['market_summary']['news_coverage']['crypto_news']}ê±´
- AI ê´€ë ¨ ë‰´ìŠ¤: {narrative['market_summary']['news_coverage']['ai_news']}ê±´
- ë³¸ë¬¸ ë°ì´í„° í™œìš©: {'ì˜ˆ' if narrative['data_quality']['has_content'] else 'ì•„ë‹ˆì˜¤'}

ğŸ”¥ í•µì‹¬ ì—”í‹°í‹° (ì¤‘ìš”ë„ìˆœ):
"""

        # ìƒìœ„ ì—”í‹°í‹°
        for i, (entity, score) in enumerate(
            narrative["market_summary"]["top_entities"][:5], 1
        ):
            context += f"- {entity}: {score}ì \n"

        context += f"""
ğŸ¯ ì£¼ìš” í…Œë§ˆ:
"""

        # ì£¼ìš” í…Œë§ˆ
        for i, theme in enumerate(narrative["market_summary"]["main_themes"][:3], 1):
            entities_str = ", ".join(theme["entities"])
            context += f"- {theme['theme']}: {entities_str} (ì¤‘ìš”ë„: {theme['importance']:.1f})\n"

        context += f"""
âš¡ ì˜í–¥ ê´€ê³„:
"""

        # ì˜í–¥ ì²´ì¸
        for chain in narrative["market_summary"]["impact_chains"][:3]:
            source = chain["source"]
            positive = (
                ", ".join(chain["positive_impact"])
                if chain["positive_impact"]
                else "ì—†ìŒ"
            )
            context += f"- {source} â†’ ê¸ì •ì  ì˜í–¥: {positive}\n"

        context += f"""
ğŸ“° ì£¼ìš” ë‰´ìŠ¤ (ìƒìœ„ 3ê°œ):
"""

        # ì¤‘ìš”ë„ ë†’ì€ ë‰´ìŠ¤ (ë³¸ë¬¸ ë‚´ìš© í¬í•¨)
        sorted_news = sorted(
            financial_data.get("news", []),
            key=lambda x: x.importance_score,
            reverse=True,
        )
        for i, news in enumerate(sorted_news[:3], 1):
            context += f"{i}. {news.title} (ì¤‘ìš”ë„: {news.importance_score})\n"
            context += f"   ì—”í‹°í‹°: {', '.join(news.entities)}\n"
            if hasattr(news, "summary") and news.summary:
                context += f"   ë‚´ìš©: {news.summary[:150]}...\n"

        return context
