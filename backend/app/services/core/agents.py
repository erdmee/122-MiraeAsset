import os
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any

# ìƒˆë¡œìš´ í†µí•© ë„êµ¬ë“¤ import
try:
    from app.services.core.elasticsearch_tool import (
        search_financial_documents,
        get_available_companies,
        get_document_types,
    )

    # graph_rag_toolì€ ë”ì´ìƒ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë”ë¯¸ í•¨ìˆ˜ ì‚¬ìš©
    def search_company_news(query, **kwargs):
        return f"íšŒì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰: {query}"

    def find_related_companies(company, **kwargs):
        return f"{company}ì™€ ê´€ë ¨ëœ íšŒì‚¬ë“¤"

    def get_market_trends(**kwargs):
        return "ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„"

    def get_graph_statistics(**kwargs):
        return "ê·¸ë˜í”„ í†µê³„"

except ImportError as e:
    print(f"ìƒˆë¡œìš´ ë„êµ¬ import ì‹¤íŒ¨: {e}")

    # ë”ë¯¸ í•¨ìˆ˜ë“¤
    def search_financial_documents(query, **kwargs):
        return f"Elasticsearch ê²€ìƒ‰: {query}"

    def get_available_companies():
        return "ë“±ë¡ëœ ê¸°ì—… ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def get_document_types():
        return "ë¬¸ì„œ íƒ€ì…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def search_company_news(company_name, limit=5):
        return f"{company_name} ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼"

    def find_related_companies(company_name):
        return f"{company_name} ê´€ë ¨ ê¸°ì—… ê²€ìƒ‰ ê²°ê³¼"

    def get_market_trends(days=7):
        return f"ìµœê·¼ {days}ì¼ ì‹œì¥ íŠ¸ë Œë“œ"

    def get_graph_statistics():
        return "ê·¸ë˜í”„ í†µê³„ ì •ë³´"


# ì‹¤ì œ ì›¹ ê²€ìƒ‰ ë° í¬ë¡¤ë§ ë„êµ¬ë“¤ import
try:
    from app.services.tools.websearch_tool import WebSearchTool as RealWebSearchTool

    print("RealWebSearchTool import ì„±ê³µ")
    WebSearchTool = RealWebSearchTool
except ImportError as e:
    print(f"RealWebSearchTool import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©: {e}")

    class WebSearchTool:
        def search(self, query):
            return f"ì›¹ ê²€ìƒ‰ ë”ë¯¸ ê²°ê³¼: {query}"


try:
    from app.services.tools.playwright_tool import PlaywrightTool as RealPlaywrightTool

    print("RealPlaywrightTool import ì„±ê³µ")
    PlaywrightTool = RealPlaywrightTool
except ImportError as e:
    print(f"RealPlaywrightTool import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©: {e}")

    class PlaywrightTool:
        def scrape(self, url):
            return f"Playwright ë”ë¯¸ ê²°ê³¼: {url}"


# ë ˆê±°ì‹œ ë„êµ¬ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
try:
    from app.services.tools.graphdb_tool import Neo4jGraphTool as GraphQueryTool

    print("Neo4j GraphQueryTool import ì„±ê³µ")
except ImportError:
    print("Neo4j GraphQueryTool import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©")

    class GraphQueryTool:
        def query(self, q):
            return f"GraphDB ê²°ê³¼: {q}"

        def query_graph_context(self, q, limit=10):
            return {"query": q, "entities": [], "relationships": []}


# GraphRAGProcessorëŠ” ë³„ë„ë¡œ ì •ì˜
class GraphRAGProcessor:
    def query_with_graph_context(self, q):
        return {
            "query": q,
            "extracted_entities": [],
            "neighbors": [],
            "relationships": [],
        }

    def build_context_prompt(self, q, data):
        return f"ì§ˆë¬¸: {q}"


try:
    from app.services.core.elasticsearch_tool import (
        ElasticsearchQueryTool as VectorQueryTool,
    )

    print("ElasticsearchQueryTool import ì„±ê³µ")
except ImportError:
    print("ElasticsearchQueryTool import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©")

    class VectorQueryTool:
        def search(self, q):
            return f"Elasticsearch ê²°ê³¼: {q}"

    class GraphQueryTool:
        def query(self, q):
            return f"GraphDB ê²°ê³¼: {q}"

        def query_graph_context(self, q, limit=10):
            return {"query": q, "entities": [], "relationships": []}

    class GraphRAGProcessor:
        def query_with_graph_context(self, q):
            return {
                "query": q,
                "extracted_entities": [],
                "neighbors": [],
                "relationships": [],
            }

        def build_context_prompt(self, q, data):
            return f"ì§ˆë¬¸: {q}"


try:
    from app.services.tools.sqlite_tool import SQLiteTool
except ImportError:
    print("SQLiteTool import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©")

    class SQLiteTool:
        def query(self, q):
            return f"SQLite ê²°ê³¼: {q}"


try:
    from app.services.external.hyperclova_client import HyperClovaXClient
except ImportError:
    print("HyperClovaXClient import ì‹¤íŒ¨ - ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©")

    class HyperClovaXClient:
        def chat_completion(self, **kwargs):
            return {"content": "ë”ë¯¸ ì‘ë‹µì…ë‹ˆë‹¤."}


class ClovaXLLM:
    """HyperCLOVA X ë˜í¼"""

    def __init__(self):
        try:
            from app.services.external.hyperclova_client import HyperClovaXClient

            self.client = HyperClovaXClient()
            print("ClovaXLLM: HyperCLOVA X í´ë¼ì´ì–¸íŠ¸ë¡œ ì´ˆê¸°í™”ë¨")
        except Exception as e:
            print(f"HyperCLOVA X í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ClovaXLLM: ë”ë¯¸ ëª¨ë“œë¡œ ì´ˆê¸°í™”ë¨")
            self.client = None

    def chat(self, prompt: str) -> str:
        """HyperCLOVA Xë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
        if self.client:
            try:
                response = self.client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=2048,
                )
                if response:
                    # HyperClovaXResponse ê°ì²´ì—ì„œ content ì¶”ì¶œ
                    if hasattr(response, "get_content"):
                        return response.get_content()
                    elif hasattr(response, "content"):
                        return response.content
                    elif hasattr(response, "get"):
                        return response.get("content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        return str(response)
                return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            except Exception as e:
                print(f"HyperCLOVA X API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                # API ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ì‘ë‹µ
                return self._dummy_response(prompt)
        else:
            return self._dummy_response(prompt)

    def _dummy_response(self, prompt: str) -> str:
        """ê°œì„ ëœ ë”ë¯¸ ì‘ë‹µ ìƒì„± - í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì— ë§ëŠ” ì‘ë‹µ"""
        print(f"ë”ë¯¸ LLM í˜¸ì¶œ: {prompt[:50]}...")

        prompt_lower = prompt.lower()

        # ì§ˆë¬¸ ë¶„ë¥˜ ê´€ë ¨
        if "classification" in prompt_lower and "simple" in prompt_lower:
            if any(
                word in prompt_lower
                for word in ["ì•ˆë…•", "í•˜ì´", "hi", "hello", "ì‹œê°„", "ë‚ ì§œ"]
            ):
                return '{"classification": "simple", "reason": "ì¸ì‚¬ë§ ë˜ëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ê°„ë‹¨í•œ ì‘ë‹µì´ ì í•©í•©ë‹ˆë‹¤."}'
            else:
                return '{"classification": "complex", "reason": "íˆ¬ì ê´€ë ¨ ì „ë¬¸ ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤."}'

        # ì¿¼ë¦¬ ë¶„í•´ ê´€ë ¨
        elif "ë¶„í•´" in prompt or "í•˜ìœ„" in prompt or "ì¿¼ë¦¬" in prompt:
            return '["ê¸°ì—… ìµœê·¼ ì‹¤ì  ë° ì¬ë¬´ ìƒíƒœ", "ì—…ê³„ ì‹œì¥ ë™í–¥ ë° ì „ë§", "ì£¼ê°€ ê¸°ìˆ ì  ë¶„ì„ ë° ëª©í‘œê°€"]'

        # ë„êµ¬ ì„ íƒ ê´€ë ¨
        elif "ë„êµ¬" in prompt or "tool" in prompt:
            if "ë‰´ìŠ¤" in prompt or "ìµœì‹ " in prompt:
                return '{"tool": "company_news", "reason": "ìµœì‹  ë‰´ìŠ¤ ì •ë³´ê°€ í•„ìš”í•˜ì—¬ company_news ë„êµ¬ê°€ ì í•©í•©ë‹ˆë‹¤."}'
            elif "ì¬ë¬´" in prompt or "ì‹¤ì " in prompt or "ê³µì‹œ" in prompt:
                return '{"tool": "financial_search", "reason": "ì¬ë¬´ ë°ì´í„° ê²€ìƒ‰ì„ ìœ„í•´ financial_search ë„êµ¬ê°€ ì í•©í•©ë‹ˆë‹¤."}'
            else:
                return '{"tool": "websearch", "reason": "ì¼ë°˜ì ì¸ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•´ websearch ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."}'

        # ê¸°ì—…ëª… ì¶”ì¶œ ê´€ë ¨
        elif "company" in prompt_lower and "ì¶”ì¶œ" in prompt:
            if "ì‚¼ì„±" in prompt:
                return '{"company": "ì‚¼ì„±ì „ì", "confidence": "ë†’ìŒ"}'
            elif "lg" in prompt_lower:
                return '{"company": "LGì „ì", "confidence": "ë†’ìŒ"}'
            else:
                return '{"company": "", "confidence": "ë‚®ìŒ"}'

        # ì •ë³´ í‰ê°€ ê´€ë ¨
        elif "í‰ê°€" in prompt or "sufficiency" in prompt_lower:
            return '{"sufficiency": true, "feedback": "ìˆ˜ì§‘ëœ ì •ë³´ê°€ íˆ¬ì ì˜ì‚¬ê²°ì •ì— ì¶©ë¶„í•©ë‹ˆë‹¤."}'

        # ì¼ë°˜ì ì¸ íˆ¬ì ì¸ì‚¬ì´íŠ¸
        else:
            return """# íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸

## í•µì‹¬ ìš”ì•½
í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ì‹œì¥ ë™í–¥
- ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ íë¦„ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤
- ê±°ë˜ëŸ‰ì´ í‰ì†Œ ëŒ€ë¹„ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤
- ê¸°ê´€íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤

## íˆ¬ì ì œì•ˆ
- **ë‹¨ê¸°**: ì‹ ì¤‘í•œ ì ‘ê·¼ ê¶Œì¥
- **ì¤‘ì¥ê¸°**: ì„ ë³„ì  íˆ¬ì ê²€í†  ê°€ëŠ¥
- **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚° í•„ìˆ˜

## ì£¼ì˜ì‚¬í•­
ë³¸ ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ íˆ¬ì ê²°ì • ì‹œì—ëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

**ë©´ì±…ì¡°í•­**: íˆ¬ìì—ëŠ” ì›ê¸ˆ ì†ì‹¤ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤."""


# SimpleAgent - ë‹¨ìˆœí•œ ì§ˆë¬¸ì— ë°”ë¡œ ì‘ë‹µ
class SimpleAgent:
    def __init__(self, llm=None):
        self.llm = llm or ClovaXLLM()

    async def is_simple_query(self, query: str) -> bool:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ìˆœí•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        prompt = f"""ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¨ìˆœí•œ ì§ˆë¬¸ì¸ì§€ ë³µì¡í•œ íˆ¬ì ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**ì—­í• **: ì§ˆë¬¸ ë¶„ë¥˜ ì „ë¬¸ê°€
**ëª©í‘œ**: ì§ˆë¬¸ì„ Simple ë˜ëŠ” Complexë¡œ ë¶„ë¥˜

**ë¶„ë¥˜ ê¸°ì¤€**:
- **Simple**: ì¸ì‚¬ë§, ì‹œê°„ ë¬¸ì˜, ê¸°ëŠ¥ ì„¤ëª…, ë‹¨ìˆœí•œ ì•ˆë¶€, ì¼ë°˜ì ì¸ ëŒ€í™”
- **Complex**: íˆ¬ì ë¶„ì„, ê¸°ì—… ì •ë³´, ì‹œì¥ ë™í–¥, ì¬ë¬´ ë°ì´í„°, ì¢…ëª© ë¶„ì„ ë“± ì „ë¬¸ì ì¸ ê¸ˆìœµ ì§ˆë¬¸

**ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

**ì‚¬ê³  ê³¼ì •**:
1. ì§ˆë¬¸ì˜ ì˜ë„ íŒŒì•…
2. íˆ¬ì/ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
3. ì „ë¬¸ì ì¸ ë¶„ì„ì´ í•„ìš”í•œì§€ íŒë‹¨
4. ìµœì¢… ë¶„ë¥˜ ê²°ì •

**ì‘ë‹µ í˜•ì‹**: {{"classification": "simple" ë˜ëŠ” "complex", "reason": "ë¶„ë¥˜ ì´ìœ "}}

ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            response = self.llm.chat(prompt)
            import re
            import json

            # JSON íŒ¨í„´ ì°¾ê¸°
            json_pattern = r'\{[^}]*"classification"[^}]*\}'
            matches = re.search(json_pattern, response)

            if matches:
                result = json.loads(matches.group())
                return result.get("classification", "complex").lower() == "simple"

            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¶„ì„
            response_lower = response.lower()
            return "simple" in response_lower and "complex" not in response_lower

        except Exception as e:
            print(f"ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ì ìœ¼ë¡œ complexë¡œ ì²˜ë¦¬ (ì•ˆì „í•œ ì„ íƒ)
            return False

    async def generate_simple_response(self, query: str) -> str:
        """LLMì„ ì‚¬ìš©í•œ ë‹¨ìˆœ ì§ˆë¬¸ ì‘ë‹µ ìƒì„±"""
        current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")
        current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        current_weekday = datetime.now().strftime("%A")
        weekday_korean = {
            "Monday": "ì›”ìš”ì¼",
            "Tuesday": "í™”ìš”ì¼",
            "Wednesday": "ìˆ˜ìš”ì¼",
            "Thursday": "ëª©ìš”ì¼",
            "Friday": "ê¸ˆìš”ì¼",
            "Saturday": "í† ìš”ì¼",
            "Sunday": "ì¼ìš”ì¼",
        }

        prompt = f"""ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ AI íˆ¬ì ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

**ì—­í• **: ë¯¸ë˜ì—ì…‹ AI íˆ¬ì ì–´ì‹œìŠ¤í„´íŠ¸
**ì„±ê²©**: ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì „ë¬¸ê°€
**ëª©í‘œ**: ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ì œê³µ

**í˜„ì¬ ì •ë³´**:
- í˜„ì¬ ì‹œê°„: {current_time}
- ì˜¤ëŠ˜ ë‚ ì§œ: {current_date} ({weekday_korean.get(current_weekday, current_weekday)})

**ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

**ì‘ë‹µ ì§€ì¹¨**:
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
2. í•„ìš”ì‹œ í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ì •ë³´ í™œìš©
3. íˆ¬ì ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œì˜ ì—­í• ê³¼ ê¸°ëŠ¥ ì†Œê°œ
4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš© (ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€)
5. ê°„ê²°í•˜ë©´ì„œë„ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì œê³µ

**ì‚¬ê³  ê³¼ì •**:
1. ì§ˆë¬¸ì˜ ì˜ë„ íŒŒì•…
2. ì ì ˆí•œ ì‘ë‹µ ìœ í˜• ê²°ì • (ì¸ì‚¬, ì‹œê°„, ê¸°ëŠ¥ ì„¤ëª… ë“±)
3. ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë  ì¶”ê°€ ì •ë³´ ê³ ë ¤
4. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ìœ ì§€

ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”:"""

        try:
            return self.llm.chat(prompt)
        except Exception as e:
            print(f"Simple ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"""ì•ˆë…•í•˜ì„¸ìš”.

í˜„ì¬ ì‹œê°„ì€ **{current_time}**ì…ë‹ˆë‹¤.

ì €ëŠ” ë¯¸ë˜ì—ì…‹ AI íˆ¬ì ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

## ì£¼ìš” ê¸°ëŠ¥
- **ê¸°ì—… ë¶„ì„**: ì¬ë¬´ì œí‘œ, ì‹¤ì , ì „ë§ ë¶„ì„
- **ì‹œì¥ ë™í–¥**: ìµœì‹  ë‰´ìŠ¤ì™€ ì‹œì¥ íŠ¸ë Œë“œ
- **íˆ¬ì ì¸ì‚¬ì´íŠ¸**: ë§ì¶¤í˜• íˆ¬ì ì¡°ì–¸
- **ì¢…ëª© ê²€ìƒ‰**: ê´€ì‹¬ ê¸°ì—… ì •ë³´ ì¡°íšŒ

ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”."""


# PlanningAgent - ì§€ëŠ¥ì  ì¿¼ë¦¬ ë¶„í•´ ë° ë„êµ¬ ê¸°ë°˜ ê³„íš
class PlanningAgent:
    def __init__(self, llm=None):
        self.llm = llm or ClovaXLLM()

        # ë„êµ¬ë³„ íŠ¹í™” ì¿¼ë¦¬ íŒ¨í„´
        self.tool_patterns = {
            "financial_search": [
                "ì¬ë¬´",
                "ì‹¤ì ",
                "ì˜ì—…ì´ìµ",
                "ë§¤ì¶œ",
                "ê³µì‹œ",
                "ì‚¬ì—…ë³´ê³ ì„œ",
                "ì¬ë¬´ì œí‘œ",
                "ROE",
                "PER",
                "PBR",
            ],
            "company_news": [
                "ë‰´ìŠ¤",
                "ìµœì‹ ",
                "ë°œí‘œ",
                "ì†Œì‹",
                "ì–¸ë¡ ",
                "ë³´ë„",
                "ê¸°ì‚¬",
                "ì´ìŠˆ",
            ],
            "websearch": [
                "ì „ë§",
                "ë¶„ì„",
                "ì˜ê²¬",
                "ì‹œì¥",
                "ì—…ê³„",
                "ë™í–¥",
                "íŠ¸ë Œë“œ",
                "í™˜ê²½",
            ],
            "graph_search": [
                "ê´€ê³„",
                "ì—°ê´€",
                "ê³„ì—´ì‚¬",
                "íŒŒíŠ¸ë„ˆ",
                "ê³µê¸‰ë§",
                "ê´€ë ¨ ê¸°ì—…",
                "ì—…ì¢…",
            ],
        }

    async def plan(
        self, query: str, critic_feedback: str = None
    ) -> List[Dict[str, str]]:
        """ì§€ëŠ¥ì  ì¿¼ë¦¬ ë¶„í•´ ë° ë„êµ¬ ê¸°ë°˜ ê³„íš ìˆ˜ë¦½"""
        print(f"Planning ì‹œì‘: {query}")

        # 1. ê¸°ë³¸ ë¶„í•´
        base_queries = await self._decompose_query(query, critic_feedback)

        # 2. ë„êµ¬ë³„ ìµœì í™”
        optimized_plan = await self._optimize_for_tools(base_queries, query)

        # 3. ì¤‘ìš”ë„ ì •ë ¬
        prioritized_plan = self._prioritize_queries(optimized_plan, query)

        print(f"ìµœì¢… ê³„íš: {prioritized_plan}")
        return prioritized_plan

    async def _decompose_query(
        self, query: str, critic_feedback: str = None
    ) -> List[str]:
        """ê¸°ë³¸ ì¿¼ë¦¬ ë¶„í•´"""
        try:
            feedback_section = ""
            if critic_feedback:
                feedback_section = f"\n\n**ì´ì „ í”¼ë“œë°± ë°˜ì˜**:\n{critic_feedback}"

            prompt = f"""íˆ¬ì ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•„ìš”í•œ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•´ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ë¶„í•´í•˜ì„¸ìš”.

**ì›ë³¸ ì§ˆë¬¸**: {query}{feedback_section}

**ë¶„í•´ ì§€ì¹¨**:
1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ íŒŒì•…
2. íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ì •ë³´ ì‹ë³„
3. ê° ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ êµ¬ì²´ì  ì¿¼ë¦¬ ìƒì„±
4. ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì¹˜ (ê¸°ë³¸ ì •ë³´ â†’ ìƒì„¸ ë¶„ì„)

**ë„êµ¬ë³„ ì •ë³´ ìœ í˜•**:
- **ì¬ë¬´/ì‹¤ì **: ì¬ë¬´ì œí‘œ, ì˜ì—…ì‹¤ì , ìˆ˜ìµì„± ì§€í‘œ
- **ë‰´ìŠ¤/ì´ìŠˆ**: ìµœì‹  ë™í–¥, ê²½ì˜ì§„ ë°œí‘œ, ì´ìŠˆ
- **ì‹œì¥/ì—…ê³„**: ì—…ì¢… ë¶„ì„, ê²½ìŸì‚¬, ì‹œì¥ í™˜ê²½
- **ê´€ê³„/ì—°ê´€**: ê³„ì—´ì‚¬, íŒŒíŠ¸ë„ˆì‹­, ê³µê¸‰ë§

**ì¶œë ¥ í˜•ì‹**: ["í•˜ìœ„ì¿¼ë¦¬1", "í•˜ìœ„ì¿¼ë¦¬2", "í•˜ìœ„ì¿¼ë¦¬3"]

**ì‚¬ê³  ê³¼ì •**:
1. ì§ˆë¬¸ ë¶„ì„: {query}
2. í•„ìš” ì •ë³´ ì‹ë³„
3. í•˜ìœ„ ì¿¼ë¦¬ ìƒì„±
4. ë…¼ë¦¬ì  ìˆœì„œ ë°°ì¹˜

í•˜ìœ„ ì¿¼ë¦¬ë“¤ì„ ìƒì„±í•˜ì„¸ìš”:"""

            import asyncio

            try:
                response = await asyncio.wait_for(
                    asyncio.to_thread(self.llm.chat, prompt), timeout=30.0
                )
            except asyncio.TimeoutError:
                print("ì¿¼ë¦¬ ë¶„í•´ íƒ€ì„ì•„ì›ƒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self._fallback_decompose(query)

            # JSON ì¶”ì¶œ
            queries = self._extract_queries_from_response(response)
            return queries if queries else self._fallback_decompose(query)

        except Exception as e:
            print(f"ì¿¼ë¦¬ ë¶„í•´ ì‹¤íŒ¨: {e}")
            return self._fallback_decompose(query)

    async def _optimize_for_tools(
        self, queries: List[str], original_query: str
    ) -> List[Dict[str, str]]:
        """ê° ì¿¼ë¦¬ì— ìµœì  ë„êµ¬ ë°°ì •"""
        optimized = []

        for query in queries:
            tool = await self._select_best_tool(query, original_query)
            optimized_query = await self._optimize_query_for_tool(query, tool)

            optimized.append(
                {"query": optimized_query, "tool": tool, "original": query}
            )

        return optimized

    async def _select_best_tool(self, query: str, context: str = "") -> str:
        """ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ ì„ íƒ"""
        query_lower = query.lower()

        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ 1ì°¨ ì„ íƒ
        tool_scores = {}
        for tool, patterns in self.tool_patterns.items():
            score = sum(1 for pattern in patterns if pattern in query_lower)
            if score > 0:
                tool_scores[tool] = score

        # ìµœê³  ì ìˆ˜ ë„êµ¬ ì„ íƒ
        if tool_scores:
            best_tool = max(tool_scores, key=tool_scores.get)
            print(
                f"ë„êµ¬ ì„ íƒ: '{query}' â†’ {best_tool} (ì ìˆ˜: {tool_scores[best_tool]})"
            )
            return best_tool

        # LLM ê¸°ë°˜ ì„ íƒ (íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ)
        try:
            prompt = f"""ë‹¤ìŒ ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.

**ì¿¼ë¦¬**: {query}
**ì „ì²´ ë§¥ë½**: {context}

**ë„êµ¬ ì˜µì…˜**:
1. **financial_search**: ì¬ë¬´ì œí‘œ, ì‹¤ì , ê³µì‹œ ì •ë³´
2. **company_news**: ìµœì‹  ë‰´ìŠ¤, ë°œí‘œ, ì´ìŠˆ
3. **websearch**: ì¼ë°˜ ë¶„ì„, ì‹œì¥ ë™í–¥, ì „ë§
4. **graph_search**: ê¸°ì—…ê°„ ê´€ê³„, ì—°ê´€ì„± ë¶„ì„

**ì„ íƒ ê¸°ì¤€**:
- ì¬ë¬´ ë°ì´í„°ê°€ í•„ìš”í•˜ë©´ â†’ financial_search
- ìµœì‹  ì†Œì‹ì´ í•„ìš”í•˜ë©´ â†’ company_news
- ì‹œì¥ ë¶„ì„ì´ í•„ìš”í•˜ë©´ â†’ websearch
- ê¸°ì—… ê´€ê³„ê°€ í•„ìš”í•˜ë©´ â†’ graph_search

**ì‘ë‹µ í˜•ì‹**: {{"tool": "ë„êµ¬ëª…", "reason": "ì„ íƒ ì´ìœ "}}

ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:"""

            response = self.llm.chat(prompt)

            import re, json

            json_match = re.search(r'\{[^}]*"tool"[^}]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                tool = result.get("tool", "websearch")
                print(f"LLM ë„êµ¬ ì„ íƒ: '{query}' â†’ {tool}")
                return tool

        except Exception as e:
            print(f"ë„êµ¬ ì„ íƒ ì‹¤íŒ¨: {e}")

        # ê¸°ë³¸ê°’
        return "websearch"

    async def _optimize_query_for_tool(self, query: str, tool: str) -> str:
        """ë„êµ¬ì— ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
        tool_instructions = {
            "financial_search": "ì¬ë¬´ ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì§€í‘œë‚˜ ìˆ˜ì¹˜ í¬í•¨",
            "company_news": "ìµœì‹ ì„±ì„ ê°•ì¡°í•˜ê³  ë‰´ìŠ¤ë‚˜ ì´ìŠˆ ì¤‘ì‹¬ìœ¼ë¡œ í‘œí˜„",
            "websearch": "ì‹œì¥ ë¶„ì„ì´ë‚˜ ì „ë§ ì¤‘ì‹¬ìœ¼ë¡œ í‘œí˜„",
            "graph_search": "ê¸°ì—…ê°„ ê´€ê³„ë‚˜ ì—°ê´€ì„± ì¤‘ì‹¬ìœ¼ë¡œ í‘œí˜„",
        }

        if tool in tool_instructions:
            try:
                prompt = f"""ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ {tool} ë„êµ¬ì— ìµœì í™”í•˜ì—¬ ê°œì„ í•˜ì„¸ìš”.

**ì›ë³¸ ì¿¼ë¦¬**: {query}
**ëŒ€ìƒ ë„êµ¬**: {tool}
**ìµœì í™” ë°©í–¥**: {tool_instructions[tool]}

**ê°œì„  ì›ì¹™**:
1. ë„êµ¬ì˜ íŠ¹ì„±ì— ë§ëŠ” í‚¤ì›Œë“œ í¬í•¨
2. êµ¬ì²´ì ì´ê³  ëª…í™•í•œ í‘œí˜„ ì‚¬ìš©
3. ì˜ë¯¸ ìœ ì§€í•˜ë©´ì„œ íš¨ìœ¨ì„± í–¥ìƒ

**ì¶œë ¥**: ìµœì í™”ëœ ì¿¼ë¦¬ë§Œ ë°˜í™˜

ìµœì í™”ëœ ì¿¼ë¦¬:"""

                response = self.llm.chat(prompt)
                optimized = response.strip().strip("\"'")

                if optimized and len(optimized) > 5:
                    print(f"ì¿¼ë¦¬ ìµœì í™”: '{query}' â†’ '{optimized}' ({tool})")
                    return optimized

            except Exception as e:
                print(f"ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

        return query

    def _prioritize_queries(
        self, queries: List[Dict[str, str]], original_query: str
    ) -> List[Dict[str, str]]:
        """ì¿¼ë¦¬ ìš°ì„ ìˆœìœ„ ì •ë ¬"""
        # ë„êµ¬ë³„ ìš°ì„ ìˆœìœ„ (íˆ¬ì ì˜ì‚¬ê²°ì • ì¤‘ìš”ë„ ê¸°ì¤€)
        tool_priority = {
            "financial_search": 1,  # ì¬ë¬´ ë°ì´í„°ê°€ ê°€ì¥ ì¤‘ìš”
            "company_news": 2,  # ìµœì‹  ì´ìŠˆ ì¤‘ìš”
            "graph_search": 3,  # ê´€ê³„ ë¶„ì„
            "websearch": 4,  # ì¼ë°˜ ë¶„ì„
        }

        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        for query_info in queries:
            tool = query_info["tool"]
            query = query_info["query"].lower()

            # ê¸°ë³¸ ìš°ì„ ìˆœìœ„
            priority = tool_priority.get(tool, 5)

            # ì›ë³¸ ì§ˆë¬¸ê³¼ì˜ ìœ ì‚¬ë„ ë³´ì •
            original_lower = original_query.lower()
            similarity_bonus = 0

            # í•µì‹¬ í‚¤ì›Œë“œ ë§¤ì¹­
            if any(word in query for word in original_lower.split() if len(word) > 2):
                similarity_bonus = -0.5  # ìš°ì„ ìˆœìœ„ í–¥ìƒ

            query_info["priority"] = priority + similarity_bonus

        # ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬
        sorted_queries = sorted(queries, key=lambda x: x["priority"])

        print(
            f"ìš°ì„ ìˆœìœ„ ì •ë ¬ ì™„ë£Œ: {[(q['tool'], q['priority']) for q in sorted_queries]}"
        )
        return sorted_queries

    def _extract_queries_from_response(self, response: str) -> List[str]:
        """ì‘ë‹µì—ì„œ ì¿¼ë¦¬ ë°°ì—´ ì¶”ì¶œ"""
        import re, json

        # JSON ë°°ì—´ íŒ¨í„´
        json_pattern = r"\[(.*?)\]"
        matches = re.search(json_pattern, response, re.DOTALL)

        if matches:
            try:
                queries = json.loads(f"[{matches.group(1)}]")
                if isinstance(queries, list) and queries:
                    return [
                        q for q in queries if isinstance(q, str) and len(q.strip()) > 5
                    ]
            except json.JSONDecodeError:
                pass

        # í…ìŠ¤íŠ¸ì—ì„œ ë”°ì˜´í‘œ ì¶”ì¶œ
        quote_pattern = r'"([^"]{10,})"'
        quotes = re.findall(quote_pattern, response)
        if quotes:
            return quotes[:4]  # ìµœëŒ€ 4ê°œ

        # ì¤„ ë‹¨ìœ„ ì¶”ì¶œ
        lines = [line.strip() for line in response.split("\n")]
        queries = []
        for line in lines:
            if line and not line.startswith("#") and len(line) > 10:
                # ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì œê±°
                clean_line = re.sub(r"^[\d\.\-\*\+\s]+", "", line).strip()
                if clean_line and len(clean_line) > 5:
                    queries.append(clean_line)

        return queries[:4] if queries else []

    def _fallback_decompose(self, query: str) -> List[str]:
        """ê¸°ë³¸ ë¶„í•´ ë¡œì§ (LLM ì‹¤íŒ¨ì‹œ)"""
        query_lower = query.lower()

        # ê¸°ì—…ëª… ì¶”ì¶œ ì‹œë„
        company_patterns = ["ì‚¼ì„±", "lg", "sk", "í˜„ëŒ€", "í¬ìŠ¤ì½”", "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤"]
        company = None
        for pattern in company_patterns:
            if pattern in query_lower:
                company = pattern
                break

        queries = []

        if company:
            # ê¸°ì—… íŠ¹í™” ë¶„í•´
            if any(word in query_lower for word in ["ì‹¤ì ", "ì¬ë¬´", "ìˆ˜ìµ"]):
                queries.append(f"{company} ìµœê·¼ ë¶„ê¸° ì‹¤ì  ë° ì¬ë¬´ í˜„í™©")
            if any(word in query_lower for word in ["ë‰´ìŠ¤", "ì†Œì‹", "ë°œí‘œ"]):
                queries.append(f"{company} ìµœì‹  ë‰´ìŠ¤ ë° ì£¼ìš” ì´ìŠˆ")
            if any(word in query_lower for word in ["ì „ë§", "ë¶„ì„", "ëª©í‘œ"]):
                queries.append(f"{company} íˆ¬ì ì „ë§ ë° ë¶„ì„ê°€ ì˜ê²¬")
        else:
            # ì¼ë°˜ì  ë¶„í•´
            queries = [
                "ì£¼ìš” ê¸°ì—… ì‹¤ì  ë° ì¬ë¬´ í˜„í™©",
                "ì‹œì¥ ë™í–¥ ë° ì—…ê³„ ë¶„ì„",
                "íˆ¬ì í™˜ê²½ ë° ì „ë§",
            ]

        return queries[:3]


class RetrieverAgent:
    def __init__(self, tools: Dict[str, Any] = None, llm=None):
        self.llm = llm or ClovaXLLM()
        self.graph_rag = GraphRAGProcessor()

        # ìƒˆë¡œìš´ í†µí•© ë„êµ¬ë“¤ ì¶”ê°€
        self.financial_search = search_financial_documents
        self.company_news_search = search_company_news
        self.related_companies_search = find_related_companies
        self.market_trends = get_market_trends
        self.graph_stats = get_graph_statistics
        self.get_companies = get_available_companies
        self.get_doc_types = get_document_types

        # ë ˆê±°ì‹œ ë„êµ¬ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
        self.tools = tools or {
            "graphdb": GraphQueryTool(),
            "vectordb": VectorQueryTool(),
            "sqlite": SQLiteTool(),
            "websearch": WebSearchTool(),
            "playwright": PlaywrightTool(),
        }

    async def retrieve(self, query_plan: List[Dict[str, str]]) -> Dict[str, Any]:
        """í–¥ìƒëœ ê³„íš ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰"""
        print(f"ì •ë³´ ê²€ìƒ‰ ì‹œì‘: {len(query_plan)}ê°œ ì¿¼ë¦¬")

        all_results = {
            "financial_data": [],
            "news_data": [],
            "market_analysis": [],
            "graph_data": [],
            "metadata": {
                "total_queries": len(query_plan),
                "successful_queries": 0,
                "failed_queries": 0,
                "tools_used": set(),
            },
        }

        # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ íƒœìŠ¤í¬ë“¤
        import asyncio

        tasks = []

        for i, query_info in enumerate(query_plan):
            task = asyncio.create_task(self._execute_single_query(query_info, i))
            tasks.append(task)

        # ëª¨ë“  ì¿¼ë¦¬ ë³‘ë ¬ ì‹¤í–‰
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # ê²°ê³¼ ë¶„ë¥˜ ë° ì§‘ê³„
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    print(f"ì¿¼ë¦¬ {i} ì‹¤í–‰ ì‹¤íŒ¨: {result}")
                    all_results["metadata"]["failed_queries"] += 1
                else:
                    self._categorize_result(result, all_results)
                    all_results["metadata"]["successful_queries"] += 1
                    all_results["metadata"]["tools_used"].add(
                        result.get("tool", "unknown")
                    )

        except Exception as e:
            print(f"ë³‘ë ¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ìˆœì°¨ ì‹¤í–‰ìœ¼ë¡œ í´ë°±
            for query_info in query_plan:
                try:
                    result = await self._execute_single_query(query_info, 0)
                    self._categorize_result(result, all_results)
                    all_results["metadata"]["successful_queries"] += 1
                except Exception as ex:
                    print(f"ìˆœì°¨ ê²€ìƒ‰ ì‹¤íŒ¨: {ex}")
                    all_results["metadata"]["failed_queries"] += 1

        all_results["metadata"]["tools_used"] = list(
            all_results["metadata"]["tools_used"]
        )

        print(
            f"ê²€ìƒ‰ ì™„ë£Œ: ì„±ê³µ {all_results['metadata']['successful_queries']}, ì‹¤íŒ¨ {all_results['metadata']['failed_queries']}"
        )
        return all_results

    async def _execute_single_query(
        self, query_info: Dict[str, str], index: int
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ì¿¼ë¦¬ ì‹¤í–‰"""
        query = query_info["query"]
        tool = query_info["tool"]

        print(f"ì¿¼ë¦¬ {index} ì‹¤í–‰: {tool} - {query[:50]}...")

        try:
            # ë„êµ¬ë³„ ì‹¤í–‰
            if tool == "financial_search":
                result = await self._search_financial(query)
            elif tool == "company_news":
                result = await self._search_news(query)
            elif tool == "websearch":
                result = await self._search_web(query)
            elif tool == "graph_search":
                result = await self._search_graph(query)
            else:
                result = await self._search_web(query)  # ê¸°ë³¸ê°’

            return {
                "tool": tool,
                "query": query,
                "original": query_info.get("original", query),
                "data": result,
                "success": True,
                "index": index,
            }

        except Exception as e:
            print(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ ({tool}): {e}")
            return {
                "tool": tool,
                "query": query,
                "data": f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}",
                "success": False,
                "index": index,
            }

    async def _search_financial(self, query: str) -> Dict[str, Any]:
        """ì¬ë¬´ ë°ì´í„° ê²€ìƒ‰"""
        try:
            # ê¸°ì—…ëª… ì¶”ì¶œ
            company = await self._extract_company_name(query)

            if company:
                # íŠ¹ì • ê¸°ì—… ì¬ë¬´ ê²€ìƒ‰
                financial_docs = self.financial_search(
                    query=query, company_filter=company, limit=10
                )

                return {
                    "type": "financial",
                    "company": company,
                    "documents": financial_docs,
                    "query": query,
                }
            else:
                # ì¼ë°˜ ì¬ë¬´ ê²€ìƒ‰
                financial_docs = self.financial_search(query=query, limit=5)
                return {
                    "type": "financial",
                    "documents": financial_docs,
                    "query": query,
                }

        except Exception as e:
            print(f"ì¬ë¬´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"type": "financial", "error": str(e), "query": query}

    async def _search_news(self, query: str) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            # ê¸°ì—…ëª… ì¶”ì¶œ
            company = await self._extract_company_name(query)

            if company:
                news_docs = self.company_news_search(
                    query=query, company_filter=company, limit=8
                )
            else:
                news_docs = self.company_news_search(query=query, limit=5)

            return {
                "type": "news",
                "company": company,
                "articles": news_docs,
                "query": query,
            }

        except Exception as e:
            print(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"type": "news", "error": str(e), "query": query}

    async def _search_web(self, query: str) -> Dict[str, Any]:
        """ì›¹ ê²€ìƒ‰"""
        try:
            web_tool = self.tools["websearch"]
            web_results = web_tool.search(query)

            return {"type": "web", "results": web_results, "query": query}

        except Exception as e:
            print(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"type": "web", "error": str(e), "query": query}

    async def _search_graph(self, query: str) -> Dict[str, Any]:
        """ê·¸ë˜í”„ ê²€ìƒ‰"""
        try:
            # ê¸°ì—…ëª… ì¶”ì¶œ
            company = await self._extract_company_name(query)

            if company:
                # ê´€ë ¨ ê¸°ì—… ê²€ìƒ‰
                related_companies = self.related_companies_search(
                    company=company,
                    relation_types=["ê³„ì—´ì‚¬", "í˜‘ë ¥ì‚¬", "ê³µê¸‰ì—…ì²´"],
                    limit=10,
                )

                # ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸
                graph_context = self.graph_rag.query_with_graph_context(query)

                return {
                    "type": "graph",
                    "company": company,
                    "related_companies": related_companies,
                    "graph_context": graph_context,
                    "query": query,
                }
            else:
                # ì¼ë°˜ ê·¸ë˜í”„ ê²€ìƒ‰
                graph_context = self.graph_rag.query_with_graph_context(query)
                return {"type": "graph", "graph_context": graph_context, "query": query}

        except Exception as e:
            print(f"ê·¸ë˜í”„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"type": "graph", "error": str(e), "query": query}

    async def _extract_company_name(self, query: str) -> str:
        """ì¿¼ë¦¬ì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ"""
        try:
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ì—…ëª…ì„ ì¶”ì¶œí•˜ì„¸ìš”. ì •í™•í•œ ê¸°ì—…ëª…ë§Œ ë°˜í™˜í•˜ê³ , í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.

**í…ìŠ¤íŠ¸**: {query}

**ì¶”ì¶œ ê·œì¹™**:
1. ì •í™•í•œ ê¸°ì—…ëª…ë§Œ ì¶”ì¶œ (ì˜ˆ: ì‚¼ì„±ì „ì, LGì „ì, í˜„ëŒ€ìë™ì°¨)
2. ì—…ì¢…ëª…ì´ë‚˜ ì¼ë°˜ëª…ì‚¬ëŠ” ì œì™¸
3. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜

**ì‘ë‹µ í˜•ì‹**: {{"company": "ê¸°ì—…ëª…", "confidence": "ë†’ìŒ/ë‚®ìŒ"}}

ê¸°ì—…ëª…ì„ ì¶”ì¶œí•˜ì„¸ìš”:"""

            response = self.llm.chat(prompt)

            import re, json

            json_match = re.search(r'\{[^}]*"company"[^}]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                company = result.get("company", "").strip()
                confidence = result.get("confidence", "ë‚®ìŒ")

                if company and confidence == "ë†’ìŒ":
                    return company

            # íŒ¨í„´ ë§¤ì¹­ í´ë°±
            company_patterns = {
                "ì‚¼ì„±": "ì‚¼ì„±ì „ì",
                "lg": "LGì „ì",
                "í˜„ëŒ€ì°¨": "í˜„ëŒ€ìë™ì°¨",
                "í¬ìŠ¤ì½”": "í¬ìŠ¤ì½”",
                "ë„¤ì´ë²„": "ë„¤ì´ë²„",
                "ì¹´ì¹´ì˜¤": "ì¹´ì¹´ì˜¤",
            }

            query_lower = query.lower()
            for pattern, company in company_patterns.items():
                if pattern in query_lower:
                    return company

            return ""

        except Exception as e:
            print(f"ê¸°ì—…ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def _categorize_result(self, result: Dict[str, Any], all_results: Dict[str, Any]):
        """ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        if not result.get("success", False):
            return

        data = result.get("data", {})
        tool = result.get("tool", "unknown")

        if tool == "financial_search":
            all_results["financial_data"].append(data)
        elif tool == "company_news":
            all_results["news_data"].append(data)
        elif tool == "graph_search":
            all_results["graph_data"].append(data)
        else:  # websearch ë“±
            all_results["market_analysis"].append(data)

    # ë ˆê±°ì‹œ ë©”ì†Œë“œ (í•˜ìœ„ í˜¸í™˜ì„±)
    def retrieve(self, sub_queries: List[str]) -> List[Dict]:
        """LLMì„ ì‚¬ìš©í•œ ì§€ëŠ¥ì  ì •ë³´ ê²€ìƒ‰"""
        results = []
        for q in sub_queries:
            prompt = f"""ë‹¹ì‹ ì€ ì •ë³´ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ íˆ¬ì ê´€ë ¨ ì¿¼ë¦¬ì— ëŒ€í•´ ìµœì ì˜ ì •ë³´ ìˆ˜ì§‘ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

**ì—­í• **: ì •ë³´ ê²€ìƒ‰ ì „ëµ ì „ë¬¸ê°€
**ëª©í‘œ**: ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

**ë¶„ì„ ëŒ€ìƒ ì¿¼ë¦¬**: "{q}"

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤**:
1. **financial_search**: DART ê³µì‹œ ì •ë³´ ë° ì¬ë¬´ ë°ì´í„° ê²€ìƒ‰ (Elasticsearch ê¸°ë°˜)
   - ì í•©í•œ ê²½ìš°: ê¸°ì—… ì¬ë¬´ì œí‘œ, ê³µì‹œ ì •ë³´, ì‹¤ì  ë°ì´í„°, ê¸°ì—… ê¸°ë³¸ ì •ë³´
   - ë°ì´í„° íŠ¹ì„±: ê³µì‹ì , ì •í™•í•œ ì¬ë¬´ ë°ì´í„°, ê³¼ê±° ì‹¤ì 

2. **company_news**: ê¸°ì—…ë³„ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ (Graph RAG)
   - ì í•©í•œ ê²½ìš°: íŠ¹ì • ê¸°ì—…ì˜ ìµœì‹  ë™í–¥, ë‰´ìŠ¤, ì´ìŠˆ, ìµœê·¼ ë°œí‘œì‚¬í•­
   - ë°ì´í„° íŠ¹ì„±: ì‹¤ì‹œê°„ì„±, ì‹œì¥ ë°˜ì‘, ê²½ì˜ì§„ ë°œì–¸

3. **related_companies**: ê´€ë ¨ ê¸°ì—… ë° ê²½ìŸì‚¬ ê²€ìƒ‰ (Graph RAG)
   - ì í•©í•œ ê²½ìš°: ê²½ìŸì‚¬ ë¶„ì„, ì—…ê³„ ìƒíƒœê³„, íŒŒíŠ¸ë„ˆì‚¬, ê³„ì—´ì‚¬ ì •ë³´
   - ë°ì´í„° íŠ¹ì„±: ê´€ê³„í˜• ë°ì´í„°, ì—…ê³„ êµ¬ì¡°

4. **market_trends**: ì‹œì¥ íŠ¸ë Œë“œ ë° ì‚°ì—… ë¶„ì„ (Graph RAG)
   - ì í•©í•œ ê²½ìš°: ì—…ì¢…ë³„ ë™í–¥, ì‹œì¥ ì „ë§, ì‚°ì—… ì´ìŠˆ, ê±°ì‹œê²½ì œ ì˜í–¥
   - ë°ì´í„° íŠ¹ì„±: íŠ¸ë Œë“œ ë¶„ì„, ë¯¸ë˜ ì „ë§

5. **websearch**: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰
   - ì í•©í•œ ê²½ìš°: ìµœì‹  ì£¼ê°€ ì •ë³´, ì‹¤ì‹œê°„ ë‰´ìŠ¤, ì‹œì¥ ë°˜ì‘, ì†ë³´ì„± ì •ë³´
   - ë°ì´í„° íŠ¹ì„±: ì‹¤ì‹œê°„ì„±, ë‹¤ì–‘í•œ ì¶œì²˜

**ë¶„ì„ ê³¼ì •**:
1. **ì¿¼ë¦¬ ì˜ë„ ë¶„ì„**: ì–´ë–¤ ì¢…ë¥˜ì˜ ì •ë³´ë¥¼ ì°¾ê³  ìˆëŠ”ê°€?
2. **ì •ë³´ íŠ¹ì„± íŒŒì•…**: ì‹¤ì‹œê°„ì„±ì´ ì¤‘ìš”í•œê°€? ê³µì‹ì  ë°ì´í„°ê°€ í•„ìš”í•œê°€?
3. **ìµœì  ë„êµ¬ ë§¤ì¹­**: ì¿¼ë¦¬ íŠ¹ì„±ê³¼ ë„êµ¬ íŠ¹ì„±ì˜ ìµœì  ì¡°í•© ì°¾ê¸°
4. **ëŒ€ì•ˆ ë„êµ¬ ê³ ë ¤**: 1ì°¨ ë„êµ¬ ì‹¤íŒ¨ ì‹œ ë°±ì—… ì „ëµ

**ì‘ë‹µ í˜•ì‹**: {{"tool": "ë„êµ¬ëª…", "reason": "ìƒì„¸í•œ ì„ íƒ ì´ìœ ì™€ ê¸°ëŒ€ ê²°ê³¼"}}

ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”:"""

            try:
                # ë„êµ¬ ì„ íƒì„ ìœ„í•œ LLM í˜¸ì¶œ
                response = self.llm.chat(prompt)

                # JSON íŒŒì‹±
                import re
                import json

                json_pattern = r'\{[^}]*"tool"[^}]*\}'
                matches = re.search(json_pattern, response)
                if matches:
                    plan = json.loads(matches.group())
                    tool_name = plan.get("tool", "financial_search")
                    reason = plan.get("reason", "")

                    # ë„êµ¬ ì‹¤í–‰
                    if tool_name == "financial_search":
                        result = self.financial_search(q)
                    elif tool_name == "company_news":
                        company_name = self._extract_company_name_llm(q)
                        result = (
                            self.company_news_search(company_name)
                            if company_name
                            else "ê¸°ì—…ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                    elif tool_name == "related_companies":
                        company_name = self._extract_company_name_llm(q)
                        result = (
                            self.related_companies_search(company_name)
                            if company_name
                            else "ê¸°ì—…ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                    elif tool_name == "market_trends":
                        result = self.market_trends()
                    elif tool_name == "websearch":
                        print(f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹¤í–‰: {q}")
                        if "websearch" in self.tools:
                            print(f"ğŸ“¡ WebSearchToolë¡œ ê²€ìƒ‰ ì¤‘...")
                            result = self.tools["websearch"].search(q)
                            print(f"âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {str(result)[:200]}...")
                        else:
                            print(f"âŒ WebSearchTool ì—†ìŒ - ë”ë¯¸ ê²°ê³¼ ë°˜í™˜")
                            result = f"ì›¹ ê²€ìƒ‰: {q}"
                    else:
                        # ë ˆê±°ì‹œ ë„êµ¬ë“¤
                        if tool_name in self.tools:
                            if hasattr(self.tools[tool_name], "search"):
                                result = self.tools[tool_name].search(q)
                            elif hasattr(self.tools[tool_name], "query"):
                                result = self.tools[tool_name].query(q)
                            elif hasattr(self.tools[tool_name], "crawl"):
                                result = self.tools[tool_name].crawl(q)
                            else:
                                result = f"{tool_name} ë„êµ¬ ì‹¤í–‰: {q}"
                        else:
                            result = f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"

                    results.append(
                        {
                            "query": q,
                            "result": result,
                            "tool": tool_name,
                            "reason": reason,
                        }
                    )
                    continue

            except Exception as e:
                print(f"ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ websearch ì‚¬ìš©
            print(f"ğŸ”„ í´ë°±: ì›¹ ê²€ìƒ‰ ì‹¤í–‰ - {q}")
            if "websearch" in self.tools:
                result = self.tools["websearch"].search(q)
                print(f"âœ… í´ë°± ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {str(result)[:200]}...")
            else:
                result = f"ì›¹ ê²€ìƒ‰ ë„êµ¬ ì—†ìŒ: {q}"
                print(f"âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì—†ìŒ")

            results.append(
                {
                    "query": q,
                    "result": result,
                    "tool": "websearch",
                    "reason": "ë„êµ¬ ì„ íƒ ì‹¤íŒ¨ë¡œ ì¸í•œ ì›¹ ê²€ìƒ‰ í´ë°±",
                }
            )

        return results

    def _extract_company_name_llm(self, query: str) -> str:
        """LLMì„ ì‚¬ìš©í•œ ê¸°ì—…ëª… ì¶”ì¶œ"""
        prompt = f"""ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¿¼ë¦¬ì—ì„œ í•œêµ­ ê¸°ì—…ëª…ì„ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì—­í• **: ê¸°ì—…ëª… ì¶”ì¶œ ì „ë¬¸ê°€
**ëª©í‘œ**: ì¿¼ë¦¬ì—ì„œ ì •í™•í•œ í•œêµ­ ê¸°ì—…ëª… ì‹ë³„

**ë¶„ì„ ëŒ€ìƒ**: "{query}"

**ì¶”ì¶œ ì›ì¹™**:
1. ì™„ì „í•œ ê¸°ì—…ëª… ìš°ì„  (ì˜ˆ: "ì‚¼ì„±ì „ì", "LGí™”í•™")
2. ì•½ì–´ë‚˜ ë³„ëª…ë³´ë‹¤ëŠ” ì •ì‹ ëª…ì¹­
3. ê·¸ë£¹ëª…ì´ ì•„ë‹Œ ê°œë³„ ê¸°ì—…ëª… (ì˜ˆ: "ì‚¼ì„±" â†’ "ì‚¼ì„±ì „ì")
4. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…ëª…ì€ ë°˜í™˜í•˜ì§€ ì•ŠìŒ

**ì£¼ìš” í•œêµ­ ê¸°ì—… ì˜ˆì‹œ**:
- ì‚¼ì„±ì „ì, LGì „ì, SKí•˜ì´ë‹‰ìŠ¤, í˜„ëŒ€ìë™ì°¨, í¬ìŠ¤ì½”
- NAVER, ì¹´ì¹´ì˜¤, ì…€íŠ¸ë¦¬ì˜¨, í˜„ëŒ€ì¤‘ê³µì—…, í•œêµ­ì „ë ¥
- KT, LGí™”í•™, ì•„ëª¨ë ˆí¼ì‹œí”½, LGìƒí™œê±´ê°•

**ì‘ë‹µ í˜•ì‹**: {{"company": "ê¸°ì—…ëª…" ë˜ëŠ” "", "confidence": "ë†’ìŒ/ë³´í†µ/ë‚®ìŒ"}}

ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            response = self.llm.chat(prompt)
            import re
            import json

            json_pattern = r'\{[^}]*"company"[^}]*\}'
            matches = re.search(json_pattern, response)

            if matches:
                result = json.loads(matches.group())
                company = result.get("company", "")
                confidence = result.get("confidence", "ë‚®ìŒ")

                if company and confidence in ["ë†’ìŒ", "ë³´í†µ"]:
                    return company

            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
            companies = [
                "ì‚¼ì„±ì „ì",
                "LGì „ì",
                "SKí•˜ì´ë‹‰ìŠ¤",
                "í˜„ëŒ€ìë™ì°¨",
                "í¬ìŠ¤ì½”",
                "NAVER",
                "ì¹´ì¹´ì˜¤",
                "ì…€íŠ¸ë¦¬ì˜¨",
                "í˜„ëŒ€ì¤‘ê³µì—…",
                "í•œêµ­ì „ë ¥",
                "KT",
                "LGí™”í•™",
                "ì•„ëª¨ë ˆí¼ì‹œí”½",
                "LGìƒí™œê±´ê°•",
            ]

            for company in companies:
                if company in query:
                    return company

            return ""

        except Exception as e:
            print(f"ê¸°ì—…ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""


# CriticAgent1
class CriticAgent1:
    def __init__(self, llm=None):
        self.llm = llm or ClovaXLLM()

    async def evaluate(
        self, retrieved_results: Dict[str, Any], original_query: str
    ) -> Dict:
        """í–¥ìƒëœ ì •ë³´ í‰ê°€ - êµ¬ì¡°í™”ëœ ë°ì´í„° ê¸°ë°˜"""
        print(f"Evaluating structured results for: {original_query}")

        # ë°ì´í„° ìš”ì•½ ìƒì„±
        data_summary = self._summarize_retrieved_data(retrieved_results)

        prompt = f"""ë‹¹ì‹ ì€ íˆ¬ì ì •ë³´ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì •ë³´ê°€ íˆ¬ììì˜ ì§ˆë¬¸ì— ì¶©ë¶„í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.

**ì—­í• **: íˆ¬ì ì •ë³´ ì¶©ì¡±ë„ í‰ê°€ ì „ë¬¸ê°€
**ëª©í‘œ**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ì •ë³´ì˜ ì™„ì„±ë„ íŒë‹¨

**ì›ë³¸ íˆ¬ìì ì§ˆë¬¸**: "{original_query}"

**ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½**:
{data_summary}

**ê²€ìƒ‰ ë©”íƒ€ë°ì´í„°**:
- ì´ ì¿¼ë¦¬ ìˆ˜: {retrieved_results['metadata']['total_queries']}
- ì„±ê³µí•œ ê²€ìƒ‰: {retrieved_results['metadata']['successful_queries']}
- ì‹¤íŒ¨í•œ ê²€ìƒ‰: {retrieved_results['metadata']['failed_queries']}
- ì‚¬ìš©ëœ ë„êµ¬: {', '.join(retrieved_results['metadata']['tools_used'])}

**í‰ê°€ ê¸°ì¤€**:
1. **ì •ë³´ ì™„ì„±ë„**: ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ í•µì‹¬ ì •ë³´ê°€ ì¶©ë¶„í•œê°€?
2. **ì •ë³´ ë‹¤ì–‘ì„±**: ì—¬ëŸ¬ ê´€ì (ì¬ë¬´, ë‰´ìŠ¤, ì‹œì¥ ë¶„ì„)ì˜ ì •ë³´ê°€ ê· í˜•ìˆê²Œ ìˆ˜ì§‘ë˜ì—ˆëŠ”ê°€?
3. **ì •ë³´ í’ˆì§ˆ**: ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì‹ ë¢°í•  ë§Œí•˜ê³  ê´€ë ¨ì„±ì´ ë†’ì€ê°€?
4. **ìµœì‹ ì„±**: íˆ¬ì íŒë‹¨ì— í•„ìš”í•œ ìµœì‹  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?

**íŒë‹¨ ê¸°ì¤€**:
- **ì¶©ë¶„**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ê³  í’ˆì§ˆì´ ìš°ìˆ˜í•¨
- **ë¶ˆì¶©ë¶„**: ì¤‘ìš”í•œ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ì •ë³´ì˜ í’ˆì§ˆì´ ë¯¸í¡í•˜ì—¬ ì¶”ê°€ ìˆ˜ì§‘ í•„ìš”

**ì‘ë‹µ í˜•ì‹**: {{"sufficiency": true/false, "feedback": "êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš© ë° ê°œì„  ë°©í–¥", "missing_areas": ["ë¶€ì¡±í•œ ì˜ì—­1", "ë¶€ì¡±í•œ ì˜ì—­2"]}}

**í”¼ë“œë°± ì‘ì„± ì§€ì¹¨**:
- ë¶ˆì¶©ë¶„í•œ ê²½ìš°: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì •ë³´ê°€ ë” í•„ìš”í•œì§€ ëª…ì‹œí•˜ê³  ì¶”ê°€ ê²€ìƒ‰ ë°©í–¥ ì œì‹œ
- ì¶©ë¶„í•œ ê²½ìš°: ìˆ˜ì§‘ëœ ì •ë³´ì˜ ê°•ì ê³¼ íˆ¬ì íŒë‹¨ì— ë„ì›€ì´ ë˜ëŠ” ë¶€ë¶„ ìš”ì•½

í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            import asyncio

            response = await asyncio.to_thread(self.llm.chat, prompt)
            import re, json

            json_pattern = r'\{[^}]*"sufficiency"[^}]*\}'
            matches = re.search(json_pattern, response)

            if matches:
                result = json.loads(matches.group())
                if isinstance(result, dict) and "sufficiency" in result:
                    return result

            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¶„ì„
            response_lower = response.lower()
            if any(
                word in response_lower
                for word in ["ë¶ˆì¶©ë¶„", "ë¶€ì¡±", "insufficient", "ë¶€ì¡±í•˜"]
            ):
                sufficiency = False
                feedback = "ìˆ˜ì§‘ëœ ì •ë³´ê°€ íˆ¬ì ì˜ì‚¬ê²°ì •ì— ë¶€ì¡±í•©ë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                sufficiency = True
                feedback = "ìˆ˜ì§‘ëœ ì •ë³´ê°€ íˆ¬ì ì˜ì‚¬ê²°ì •ì— ì¶©ë¶„í•©ë‹ˆë‹¤."

            return {
                "sufficiency": sufficiency,
                "feedback": feedback,
                "missing_areas": [] if sufficiency else ["ì¶”ê°€ ë¶„ì„ í•„ìš”"],
            }

        except Exception as e:
            print(f"ì •ë³´ í‰ê°€ ì‹¤íŒ¨: {e}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ (ì¶©ë¶„í•¨ìœ¼ë¡œ ì²˜ë¦¬)
            return {
                "sufficiency": True,
                "feedback": "ì •ë³´ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ, ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.",
                "missing_areas": [],
            }

    def _summarize_retrieved_data(self, retrieved_results: Dict[str, Any]) -> str:
        """ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½"""
        summary_parts = []

        # ì¬ë¬´ ë°ì´í„° ìš”ì•½
        if retrieved_results["financial_data"]:
            financial_count = len(retrieved_results["financial_data"])
            summary_parts.append(f"ğŸ“Š ì¬ë¬´ ì •ë³´: {financial_count}ê°œ ë¬¸ì„œ ìˆ˜ì§‘")
            for data in retrieved_results["financial_data"][:2]:  # ìµœëŒ€ 2ê°œë§Œ
                if "company" in data:
                    summary_parts.append(f"  - {data['company']} ê´€ë ¨ ì¬ë¬´ ë°ì´í„°")

        # ë‰´ìŠ¤ ë°ì´í„° ìš”ì•½
        if retrieved_results["news_data"]:
            news_count = len(retrieved_results["news_data"])
            summary_parts.append(f"ğŸ“° ë‰´ìŠ¤ ì •ë³´: {news_count}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
            for data in retrieved_results["news_data"][:2]:  # ìµœëŒ€ 2ê°œë§Œ
                if "company" in data:
                    summary_parts.append(f"  - {data['company']} ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤")

        # ì‹œì¥ ë¶„ì„ ìš”ì•½
        if retrieved_results["market_analysis"]:
            market_count = len(retrieved_results["market_analysis"])
            summary_parts.append(f"ğŸ“ˆ ì‹œì¥ ë¶„ì„: {market_count}ê°œ ë¶„ì„ ìë£Œ")

        # ê·¸ë˜í”„ ë°ì´í„° ìš”ì•½
        if retrieved_results["graph_data"]:
            graph_count = len(retrieved_results["graph_data"])
            summary_parts.append(f"ğŸ”— ê´€ê³„ ë¶„ì„: {graph_count}ê°œ ê´€ê³„ ì •ë³´")

        return "\n".join(summary_parts) if summary_parts else "ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"

    # ë ˆê±°ì‹œ ë©”ì†Œë“œ (í•˜ìœ„ í˜¸í™˜ì„±)
    def evaluate(self, retrieved: List[Dict], original_query: str) -> Dict:
        print(f"Evaluating: {original_query}")

        prompt = f"""ë‹¹ì‹ ì€ ì •ë³´ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íˆ¬ììì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.

**ì—­í• **: ì •ë³´ ì¶©ì¡±ë„ í‰ê°€ ì „ë¬¸ê°€
**ëª©í‘œ**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ì •ë³´ì˜ ì™„ì„±ë„ íŒë‹¨
**í‰ê°€ ê¸°ì¤€**: ì •í™•ì„±, ì™„ì„±ë„, ìµœì‹ ì„±, ê´€ë ¨ì„±

**ì›ë³¸ íˆ¬ìì ì§ˆë¬¸**: "{original_query}"

**ìˆ˜ì§‘ëœ ì •ë³´**:
{json.dumps(retrieved, ensure_ascii=False, indent=2)}

**í‰ê°€ ê³¼ì •**:
1. **ì§ˆë¬¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„**: íˆ¬ììê°€ ì˜ì‚¬ê²°ì •í•˜ê¸° ìœ„í•´ í•„ìš”í•œ í•µì‹¬ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€?
2. **ì •ë³´ ì»¤ë²„ë¦¬ì§€ ê²€í† **: ìˆ˜ì§‘ëœ ì •ë³´ê°€ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ì–¼ë§ˆë‚˜ ì¶©ì¡±í•˜ëŠ”ê°€?
3. **ì •ë³´ í’ˆì§ˆ í‰ê°€**: ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì‹ ë¢°ì„±ê³¼ ìµœì‹ ì„±ì€ ì–´ë–¤ê°€?
4. **ëˆ„ë½ ì •ë³´ ì‹ë³„**: íˆ¬ì íŒë‹¨ì— í•„ìš”í•˜ì§€ë§Œ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€?

**í‰ê°€ ê¸°ì¤€**:
- **ì¶©ë¶„í•¨**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ê³  í’ˆì§ˆì´ ìš°ìˆ˜í•¨
- **ë¶ˆì¶©ë¶„í•¨**: ì¤‘ìš”í•œ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ì •ë³´ì˜ í’ˆì§ˆì´ ë¯¸í¡í•˜ì—¬ ì¶”ê°€ ìˆ˜ì§‘ í•„ìš”

**ì‘ë‹µ í˜•ì‹**: {{"sufficiency": true/false, "feedback": "êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš© ë° ê°œì„  ë°©í–¥"}}

**í”¼ë“œë°± ì‘ì„± ì§€ì¹¨**:
- ë¶€ì¡±í•œ ê²½ìš°: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì •ë³´ê°€ ë” í•„ìš”í•œì§€ ëª…ì‹œ
- ì¶©ë¶„í•œ ê²½ìš°: ìˆ˜ì§‘ëœ ì •ë³´ì˜ ê°•ì ê³¼ íˆ¬ì íŒë‹¨ì— ë„ì›€ì´ ë˜ëŠ” ë¶€ë¶„ ìš”ì•½

í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            response = self.llm.chat(prompt)
            import re

            json_pattern = r'\{[^}]*"sufficiency"[^}]*\}'
            matches = re.search(json_pattern, response)

            if matches:
                result = json.loads(matches.group())
                if isinstance(result, dict) and "sufficiency" in result:
                    return result

            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¶„ì„
            response_lower = response.lower()
            if (
                "ë¶ˆì¶©ë¶„" in response_lower
                or "ë¶€ì¡±" in response_lower
                or "insufficient" in response_lower
            ):
                sufficiency = False
            else:
                sufficiency = True

            return {"sufficiency": sufficiency, "feedback": "ì •ë³´ í‰ê°€ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."}

        except Exception as e:
            print(f"í¬ë¦¬í‹± í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                "sufficiency": True,
                "feedback": f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            }


class ContextIntegratorAgent:
    def __init__(self, llm=None):
        self.llm = llm or ClovaXLLM()
        self.graph_rag = GraphRAGProcessor()

    def integrate(self, retrieved: List[Dict], user_context: Dict = None) -> str:
        """ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""

        # Graph RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        graph_contexts = []
        for item in retrieved:
            if item.get("tool") == "graphdb" and "graph_context" in item.get(
                "result", {}
            ):
                graph_contexts.append(item["result"]["graph_context"])

        # ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ í†µí•©
        integrated_graph_context = ""
        if graph_contexts:
            all_entities = []
            all_relationships = []
            all_neighbors = []

            for ctx in graph_contexts:
                all_entities.extend(ctx.get("extracted_entities", []))
                all_relationships.extend(ctx.get("relationships", []))
                all_neighbors.extend(ctx.get("neighbors", []))

            # ì¤‘ë³µ ì œê±°
            unique_entities = list(set(all_entities))
            unique_relationships = {
                f"{r.get('source', '')}-{r.get('relationship', '')}-{r.get('target', '')}": r
                for r in all_relationships
            }.values()

            if unique_entities or unique_relationships:
                integrated_graph_context = f"""
## ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸
- **í•µì‹¬ ì—”í‹°í‹°**: {', '.join(unique_entities[:10])}
- **ì£¼ìš” ê´€ê³„**: {'; '.join([f"{r.get('source', '')} -[{r.get('relationship', '')}]-> {r.get('target', '')}" for r in list(unique_relationships)[:5]])}
- **ì—°ê´€ ì—”í‹°í‹°**: {', '.join([n.get('name', '') for n in all_neighbors[:8]])}
"""

        prompt = f"""
ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  í†µí•©í•˜ì—¬ êµ¬ì¡°í™”ëœ íˆ¬ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

{integrated_graph_context}

[ìˆ˜ì§‘ëœ ì •ë³´]
{json.dumps(retrieved, ensure_ascii=False, indent=2)}

[ì‚¬ìš©ì ì •ë³´]
{json.dumps(user_context, ensure_ascii=False, indent=2) if user_context else "ì‚¬ìš©ì ì •ë³´ ì—†ìŒ"}

[ì§€ì‹œì‚¬í•­]
1. ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ê³  êµ¬ì¡°í™”í•˜ì„¸ìš”:
   - ê¸°ì—…/ì‚°ì—… ë¶„ì„ (ê·¸ë˜í”„ ê´€ê³„ í¬í•¨)
   - ì‹œì¥ ë™í–¥
   - ì¬ë¬´/ì‹¤ì 
   - íˆ¬ìì ë™í–¥
   - ë¦¬ìŠ¤í¬ ìš”ì¸

2. ë‹¤ìŒ ìš”ì†Œë“¤ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”:
   - êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ë°ì´í„°
   - ì •ë³´ì˜ ì¶œì²˜ì™€ ì‹œì 
   - ì—”í‹°í‹° ê°„ ê´€ê³„ ë¶„ì„
   - ì‹ ë¢°ë„ í‰ê°€

3. ê·¸ë˜í”„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬:
   - ì—”í‹°í‹° ê°„ ì—°ê´€ì„± ë¶„ì„
   - ì‚°ì—… ìƒíƒœê³„ ê´€ê³„ íŒŒì•…
   - ê²½ìŸ/í˜‘ë ¥ êµ¬ì¡° ì´í•´

[ì‘ë‹µ]
íˆ¬ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
        try:
            return self.llm.chat(prompt)
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ í†µí•© ì‹¤íŒ¨: {e}")
            return (
                f"ì»¨í…ìŠ¤íŠ¸ í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n{integrated_graph_context}"
            )


# ReportGeneratorAgent
class ReportGeneratorAgent:
    def __init__(self, llm=None):
        self.llm = llm or ClovaXLLM()

    def generate(self, context: str, user_context: Dict = None) -> str:
        print(f"Generating report")
        current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")

        user_info = ""
        if user_context:
            user_info = f"""
**íˆ¬ìì í”„ë¡œí•„**:
- íˆ¬ì ì„±í–¥: {user_context.get('risk_tolerance', 'ì •ë³´ ì—†ìŒ')}
- íˆ¬ì ëª©í‘œ: {user_context.get('investment_goal', 'ì •ë³´ ì—†ìŒ')}
- íˆ¬ì ê²½í—˜: {user_context.get('experience_level', 'ì •ë³´ ì—†ìŒ')}
- ê´€ì‹¬ ë¶„ì•¼: {user_context.get('preferred_sectors', 'ì •ë³´ ì—†ìŒ')}
"""

        prompt = f"""ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ íˆ¬ì ë¶„ì„ê°€ì´ì ë¦¬í¬íŠ¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ììì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì „ë¬¸ì ì¸ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì—­í• **: ì‹œë‹ˆì–´ íˆ¬ì ë¶„ì„ê°€ & ë¦¬í¬íŠ¸ ì‘ì„± ì „ë¬¸ê°€
**ëª©í‘œ**: íˆ¬ììì˜ ì˜ì‚¬ê²°ì •ì„ ë•ëŠ” ì‹¤ìš©ì ì´ê³  ì „ë¬¸ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
**ì „ë¬¸ ì˜ì—­**: ê¸°ì—… ë¶„ì„, ì‹œì¥ ë™í–¥, íˆ¬ì ì „ëµ, ë¦¬ìŠ¤í¬ ê´€ë¦¬

**í˜„ì¬ ì‹œê°**: {current_time}
{user_info}

**ë¶„ì„ ìë£Œ**:
{context}

**ë¦¬í¬íŠ¸ ì‘ì„± ê³¼ì •**:
1. **í•µì‹¬ ì •ë³´ ì¶”ì¶œ**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ ì‹ë³„
2. **íŠ¸ë Œë“œ ë¶„ì„**: ì‹œì¥ ë™í–¥ê³¼ ê¸°ì—… ìƒí™©ì˜ ì—°ê´€ì„± íŒŒì•…
3. **ê¸°íšŒì™€ ìœ„í—˜ í‰ê°€**: íˆ¬ì ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ ìš”ì¸ ê· í˜•ì  ë¶„ì„
4. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸**: êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ì¡°ì–¸ ì œê³µ

**ë¦¬í¬íŠ¸ êµ¬ì„± ì›ì¹™**:
- íˆ¬ììê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ëª…í™•í•œ ì–¸ì–´ ì‚¬ìš©
- ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„
- ê· í˜•ì¡íŒ ì‹œê° (ê¸°íšŒì™€ ìœ„í—˜ ëª¨ë‘ ì œì‹œ)
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆ
- ì ì ˆí•œ ë©´ì±… ì¡°í•­ í¬í•¨

**ì‘ë‹µ í˜•ì‹**: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì „ë¬¸ íˆ¬ì ë¦¬í¬íŠ¸
- ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€
- êµ¬ì¡°í™”ëœ ì„¹ì…˜ êµ¬ì„±
- í•µì‹¬ í¬ì¸íŠ¸ ê°•ì¡° í‘œì‹œ
- í‘œë‚˜ ë¦¬ìŠ¤íŠ¸ ì ê·¹ í™œìš©

ë¦¬í¬íŠ¸ ì‘ì„±ì„ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            return self.llm.chat(prompt)
        except Exception as e:
            print(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"""# íˆ¬ì ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸

## ë¶„ì„ ìš”ì•½

í˜„ì¬ ì‹œì ({current_time})ì—ì„œì˜ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ë°œê²¬ì‚¬í•­
- ì‹œì¥ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í–ˆìŠµë‹ˆë‹¤
- ê´€ë ¨ ê¸°ì—…ë“¤ì˜ í˜„í™©ì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤
- íˆ¬ì ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤

### íˆ¬ì ì œì•ˆ
- ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤
- ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ í›„ ì˜ì‚¬ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
- ì „ë¬¸ê°€ì™€ì˜ ìƒë‹´ì„ ê³ ë ¤í•´ë³´ì„¸ìš”

### ë©´ì±…ì¡°í•­
ë³¸ ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©°, íˆ¬ìì—ëŠ” ì›ê¸ˆ ì†ì‹¤ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ íˆ¬ì ê²°ì • ì‹œì—ëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
