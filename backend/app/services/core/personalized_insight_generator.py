# app/services/personalized_insight_generator.py

import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json
import sqlite3
import logging

from app.config import settings
from app.services.core.enhanced_graph_rag import EnhancedGraphRAG
from app.services.storage.insight_storage import InsightStorage
from app.services.storage.user_memory import UserMemorySystem
from app.services.storage.enhanced_data_collector import EnhancedDataCollector
from app.services.external.hyperclova_client import HyperClovaXClient

logger = logging.getLogger(__name__)


class PersonalizedInsightGenerator:
    """ê°œì¸í™”ëœ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸° (Graph RAG + ë©”ëª¨ë¦¬ ê°•í™”)"""

    def __init__(self):
        self.enhanced_graph_rag = EnhancedGraphRAG()
        self.graph_rag = self.enhanced_graph_rag  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
        self.insight_storage = InsightStorage()
        self.user_memory = UserMemorySystem()
        self.data_collector = EnhancedDataCollector()
        self.llm_client = HyperClovaXClient()

        if self.llm_client.is_available():
            provider = self.llm_client.get_current_provider()
            logger.info(f"ê°œì¸í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ì‚¬ìš©: {provider})")
        else:
            logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ LLM APIê°€ ì—†ìŒ. Mock ëª¨ë“œë¡œ ì‹¤í–‰")

    async def generate_daily_insight(
        self, user_id: str, query: str = "ì˜¤ëŠ˜ì˜ ì‹œì¥ ìƒí™©ê³¼ ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„"
    ) -> Dict[str, Any]:
        """ì¼ì¼ ê°œì¸í™” ì¸ì‚¬ì´íŠ¸ ìƒì„± (Graph RAG + ë©”ëª¨ë¦¬ í™œìš©)"""

        # 1. ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        user_context = await self.user_memory.get_user_context(user_id)
        logger.info(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context.get('context_summary', 'N/A')}")

        # 2. Graph RAGë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë¶„ì„
        graph_context = await self.enhanced_graph_rag.get_real_time_graph_context(
            query, user_context
        )

        # 3. ê´€ë ¨ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
        market_data = await self._collect_personalized_market_data(
            user_context.get("holdings", []), user_context.get("interests", [])
        )

        # 4. ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ì¤‘ë³µ ë°©ì§€ ë° ì°¸ê³ )
        previous_insights = await self.insight_storage.search_insights(
            query=query, user_id=user_id, limit=3
        )

        # 5. Graph RAG ê¸°ë°˜ ê°œì¸í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insight = await self._generate_graph_enhanced_insight(
            user_context, graph_context, market_data, previous_insights
        )

        # 6. ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
        action_items = await self._extract_action_items(insight, user_context)

        # 7. ì¸ì‚¬ì´íŠ¸ ì €ì¥
        insight_id = await self.insight_storage.store_insight(
            insight_content=insight,
            user_query=query,
            user_id=user_id,
            entities=graph_context.get("entities", []),
            metadata={
                "graph_rag_used": True,
                "data_sources": ["neo4j", "elasticsearch", "real_time_news"],
                "confidence_score": 0.85,
                "user_personalization": True,
            },
        )

        # 8. ëŒ€í™” ê¸°ë¡ ì €ì¥
        await self.user_memory.save_message(
            user_id=user_id,
            session_id=f"daily_insight_{datetime.now().strftime('%Y%m%d')}",
            message_type="assistant",
            content=insight[:500],  # ìš”ì•½ë³¸ ì €ì¥
            entities=graph_context.get("entities", []),
            intent="daily_insight",
        )

        return {
            "insight": insight,
            "insight_id": insight_id,
            "action_items": action_items,
            "graph_context": graph_context,
            "market_data": market_data,
            "previous_insights": previous_insights,
            "generated_at": datetime.now().isoformat(),
            "user_context_summary": user_context.get("context_summary", ""),
        }

    async def _generate_graph_enhanced_insight(
        self,
        user_context: Dict,
        graph_context: Dict,
        market_data: Dict,
        previous_insights: List[Dict],
    ) -> str:
        """Graph RAG ê°•í™”ëœ ê°œì¸í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""

        # ì‚¬ìš©ì ë³´ìœ  ì£¼ì‹ ì •ë³´
        holdings_info = ""
        if user_context.get("holdings"):
            holdings_info = "ë³´ìœ  ì£¼ì‹:\n"
            for holding in user_context["holdings"][:5]:
                holdings_info += f"- {holding['stock_name']}: {holding['quantity']}ì£¼ (í‰ê·  {holding['avg_price']:,}ì›)\n"

        # Graph ì»¤ë®¤ë‹ˆí‹° ìš”ì•½
        communities_summary = ""
        for comm in graph_context.get("communities", [])[:3]:
            communities_summary += f"- {comm['center']}: {comm['summary']}\n"

        # ìµœì‹  ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸
        news_highlights = ""
        for news in graph_context.get("recent_news", [])[:3]:
            news_highlights += (
                f"- {news['title']} (ì¤‘ìš”ë„: {news.get('importance', 0)})\n"
            )

        # ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸ ì°¸ê³ ì‚¬í•­
        insight_context = ""
        if previous_insights:
            insight_context = "ì´ì „ ë¶„ì„ ì°¸ê³ ì‚¬í•­:\n"
            for insight in previous_insights[:2]:
                insight_context += (
                    f"- {insight['title']}: {insight['summary'][:100]}...\n"
                )

        prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ ê¸ˆìœµ íˆ¬ì ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. Graph RAGë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ì™€ ì‚¬ìš©ìì˜ ê°œì¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ë„ë¡œ ê°œì¸í™”ëœ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

=== ì‚¬ìš©ì í”„ë¡œí•„ ===
íˆ¬ì ê²½í—˜: {user_context.get('user_profile', {}).get('investment_experience', 'ë¯¸ì •')}
ìœ„í—˜ ì„±í–¥: {user_context.get('user_profile', {}).get('risk_tolerance', 'ë¯¸ì •')}
íˆ¬ì ëª©í‘œ: {', '.join(user_context.get('user_profile', {}).get('investment_goals', []))}

{holdings_info}

ìµœê·¼ ê´€ì‹¬ì‚¬: {', '.join([e[0] for e in user_context.get('frequent_entities', [])[:5]])}

=== Graph RAG ì‹¤ì‹œê°„ ë¶„ì„ ===

ğŸ¢ ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬ì„± ë¶„ì„:
{communities_summary}

ğŸ“° ìµœì‹  ì‹œì¥ ì´ìŠˆ (ì§€ë‚œ 7ì¼):
{news_highlights}

ğŸ”— ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ì¸ì‚¬ì´íŠ¸:
- ì´ {len(graph_context.get('graph_relationships', {}).get('relationships', []))}ê°œ ê´€ê³„ ë¶„ì„ë¨
- {len(graph_context.get('entities', []))}ê°œ ì—”í‹°í‹° ë°œê²¬
- {len(graph_context.get('communities', []))}ê°œ ì»¤ë®¤ë‹ˆí‹° ì‹ë³„

=== ì‹œì¥ ë°ì´í„° ===
{market_data.get('summary', 'ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...')}

{insight_context}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê°œì¸í™”ëœ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

# ğŸ“Š {datetime.now().strftime('%Yë…„ %mì›” %dì¼')} ê°œì¸í™” íˆ¬ì ì¸ì‚¬ì´íŠ¸

## ğŸ¯ í•µì‹¬ ìš”ì•½
(Graph RAG ë¶„ì„ ê¸°ë°˜ ì£¼ìš” ë°œê²¬ì‚¬í•­ 3ê°€ì§€)

## ğŸ’¼ ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ì˜í–¥ ë¶„ì„
(ë³´ìœ  ì£¼ì‹ì— ëŒ€í•œ Graph ê´€ê³„ ë¶„ì„ ê¸°ë°˜ ì˜í–¥ë„)

## ğŸ” Graph ì»¤ë®¤ë‹ˆí‹° ì¸ì‚¬ì´íŠ¸
(ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬ì„± ë¶„ì„ì„ í†µí•œ ìˆ¨ê²¨ì§„ ê¸°íšŒ ë°œêµ´)

## ğŸ“ˆ íˆ¬ì ì•¡ì…˜ ì•„ì´í…œ
1. **ì¦‰ì‹œ ê²€í† **:
2. **ì¤‘ê¸° ê´€ì°°**:
3. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**:

## âš ï¸ ì£¼ì˜ì‚¬í•­
(ê°œì¸ ìœ„í—˜ ì„±í–¥ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì£¼ì˜ì‚¬í•­)

---
*ë³¸ ë¶„ì„ì€ Graph RAG ê¸°ìˆ ì„ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì´ë©°, íˆ¬ì íŒë‹¨ ì‹œ ì¶”ê°€ì ì¸ ë¶„ì„ê³¼ ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.*
"""

        try:
            if self.llm_client.is_available():
                return await self.llm_client.generate_response(prompt)
            else:
                return self._generate_mock_insight(user_context, graph_context)
        except Exception as e:
            logger.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_mock_insight(user_context, graph_context)

    def _generate_mock_insight(self, user_context: Dict, graph_context: Dict) -> str:
        """ë”ë¯¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        return f"""
# ğŸ“Š {datetime.now().strftime('%Yë…„ %mì›” %dì¼')} ê°œì¸í™” íˆ¬ì ì¸ì‚¬ì´íŠ¸

## ğŸ¯ í•µì‹¬ ìš”ì•½
Graph RAG ë¶„ì„ì„ í†µí•´ {len(graph_context.get('entities', []))}ê°œ ì—”í‹°í‹°ì™€ {len(graph_context.get('communities', []))}ê°œ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.
í˜„ì¬ ì‹œì¥ì€ ë³µí•©ì ì¸ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ì†ì—ì„œ ìƒˆë¡œìš´ ê¸°íšŒì™€ ìœ„í—˜ì´ ê³µì¡´í•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ’¼ ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ì˜í–¥ ë¶„ì„
ë³´ìœ  ì¢…ëª©ë“¤ì´ ì†í•œ ì»¤ë®¤ë‹ˆí‹° ë„¤íŠ¸ì›Œí¬ì—ì„œ ê¸ì •ì ì¸ ì—°ì‡„ íš¨ê³¼ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.
íŠ¹íˆ ë°˜ë„ì²´ ìƒíƒœê³„ ë‚´ ê´€ê³„ì„±ì´ ê°•í™”ë˜ê³  ìˆì–´ ê´€ë ¨ ì¢…ëª©ì— ì£¼ëª©ì´ í•„ìš”í•©ë‹ˆë‹¤.

## ğŸ” Graph ì»¤ë®¤ë‹ˆí‹° ì¸ì‚¬ì´íŠ¸
ì¤‘ì‹¬ì„± ë¶„ì„ ê²°ê³¼, íŠ¹ì • ê¸°ì—…ë“¤ì´ ì—¬ëŸ¬ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì—°ê²°í•˜ëŠ” í—ˆë¸Œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì´ëŸ¬í•œ í—ˆë¸Œ ê¸°ì—…ë“¤ì˜ ë™í–¥ì´ ì „ì²´ ë„¤íŠ¸ì›Œí¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í´ ê²ƒìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.

## ğŸ“ˆ íˆ¬ì ì•¡ì…˜ ì•„ì´í…œ
1. **ì¦‰ì‹œ ê²€í† **: ì»¤ë®¤ë‹ˆí‹° í—ˆë¸Œ ê¸°ì—…ë“¤ì˜ ìµœì‹  ê³µì‹œ ë° ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§
2. **ì¤‘ê¸° ê´€ì°°**: ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë‚´ ìƒˆë¡œìš´ ì—°ê²° ê³ ë¦¬ ë°œìƒ ì—¬ë¶€ ì¶”ì 
3. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°ë„ ì ê²€ ë° ì§‘ì¤‘ ìœ„í—˜ ì™„í™”

## âš ï¸ ì£¼ì˜ì‚¬í•­
Graph RAG ë¶„ì„ì€ ê´€ê³„ì„± ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì‹œì¥ ë³€ë™ì„±ê³¼ ê°œë³„ ê¸°ì—… í€ë”ë©˜í„¸ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

---
*ë³¸ ë¶„ì„ì€ Graph RAG ê¸°ìˆ ì„ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì´ë©°, íˆ¬ì íŒë‹¨ ì‹œ ì¶”ê°€ì ì¸ ë¶„ì„ê³¼ ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.*
"""

    async def _collect_personalized_market_data(
        self, holdings: List[Dict], interests: List[Dict]
    ) -> Dict:
        """ê°œì¸í™”ëœ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ë³´ìœ  ë° ê´€ì‹¬ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±
            stock_symbols = set()

            for holding in holdings:
                stock_symbols.add(holding.get("stock_code", ""))

            for interest in interests:
                stock_symbols.add(interest.get("stock_code", ""))

            # ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘
            collected_data = await self.data_collector.collect_financial_data()

            return {
                "summary": f"{len(stock_symbols)}ê°œ ê´€ì‹¬ ì¢…ëª© ëŒ€ìƒ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ",
                "target_stocks": list(stock_symbols),
                "data_timestamp": datetime.now().isoformat(),
            }
        except Exception as e:
            logger.error(f"ê°œì¸í™” ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {"summary": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "target_stocks": []}

    async def _extract_action_items(
        self, insight: str, user_context: Dict
    ) -> List[Dict]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
            action_items = []

            if "ë§¤ìˆ˜" in insight or "íˆ¬ì" in insight:
                action_items.append(
                    {
                        "type": "investment_opportunity",
                        "priority": "high",
                        "description": "íˆ¬ì ê¸°íšŒ ê²€í†  í•„ìš”",
                        "timeline": "ì¦‰ì‹œ",
                    }
                )

            if "ìœ„í—˜" in insight or "ì£¼ì˜" in insight:
                action_items.append(
                    {
                        "type": "risk_management",
                        "priority": "medium",
                        "description": "ë¦¬ìŠ¤í¬ ìš”ì¸ ëª¨ë‹ˆí„°ë§",
                        "timeline": "ì§€ì†ì ",
                    }
                )

            if "ê³µì‹œ" in insight or "ë‰´ìŠ¤" in insight:
                action_items.append(
                    {
                        "type": "information_monitoring",
                        "priority": "medium",
                        "description": "ê´€ë ¨ ì •ë³´ ì§€ì† ëª¨ë‹ˆí„°ë§",
                        "timeline": "ì¼ì£¼ì¼",
                    }
                )

            return action_items
        except Exception as e:
            logger.error(f"ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€

    def get_user_profile_from_db(self, user_id: str) -> Dict:
        """RDBì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            conn = sqlite3.connect(self.data_collector.db_path)
            cursor = conn.cursor()
            
            # ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ
            cursor.execute('''
                SELECT investment_experience, risk_tolerance, investment_goals,
                       investment_style, preferred_sectors, investment_amount_range, news_keywords
                FROM user_profiles WHERE user_id = ?
            ''', (user_id,))
            
            profile_data = cursor.fetchone()
            
            if not profile_data:
                logger.warning(f"ì‚¬ìš©ì {user_id}ì˜ í”„ë¡œí•„ì´ ì—†ìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self.get_default_user_profile()
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ
            cursor.execute('''
                SELECT symbol, company_name, shares, avg_price, sector
                FROM user_portfolios WHERE user_id = ?
                ORDER BY company_name
            ''', (user_id,))
            
            portfolio_data = cursor.fetchall()
            conn.close()
            
            # JSON ë¬¸ìì—´ íŒŒì‹±
            import json
            investment_goals = json.loads(profile_data[2]) if profile_data[2] else []
            preferred_sectors = json.loads(profile_data[4]) if profile_data[4] else []
            news_keywords = json.loads(profile_data[6]) if profile_data[6] else []
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ë³€í™˜
            portfolio = []
            for holding in portfolio_data:
                portfolio.append([
                    holding[0],  # symbol
                    holding[1],  # company_name
                    holding[2],  # shares
                    holding[3]   # avg_price
                ])
            
            return {
                "preferences": {
                    "preferred_sectors": ','.join(preferred_sectors),
                    "investment_style": profile_data[3],
                    "risk_level": profile_data[1],
                    "news_keywords": ','.join(news_keywords)
                },
                "portfolio": portfolio,
                "user_profile": {
                    "investment_experience": profile_data[0],
                    "risk_tolerance": profile_data[1],
                    "investment_goals": investment_goals,
                    "investment_amount_range": profile_data[5]
                }
            }
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self.get_default_user_profile()
    
    def get_default_user_profile(self) -> Dict:
        """ê¸°ë³¸ ì‚¬ìš©ì í”„ë¡œí•„ ë°˜í™˜"""
        return {
            "preferences": {
                "preferred_sectors": "IT/ê¸°ìˆ ,ë°”ì´ì˜¤/ì œì•½",
                "investment_style": "ê· í˜•íˆ¬ì",
                "risk_level": "ìœ„í—˜ì¤‘ë¦½í˜•",
                "news_keywords": ""
            },
            "portfolio": [],
            "user_profile": {
                "investment_experience": "ì¤‘ê¸‰ì",
                "risk_tolerance": "ìœ„í—˜ì¤‘ë¦½í˜•",
                "investment_goals": ["ì¥ê¸°ì„±ì¥", "ìì‚°ë³´ì „"],
                "investment_amount_range": "1ì²œ-5ì²œë§Œì›"
            }
        }

    def create_personalized_script_prompt(
        self, financial_data: Dict, user_profile: Dict
    ) -> str:
        """ê°œì¸í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´ ìµœì í™”)"""
        graph_context = self.graph_rag.generate_insight_context(financial_data)
        portfolio = user_profile.get("portfolio", [])
        preferences = user_profile.get("preferences", {})
        user_info = user_profile.get("user_profile", {})

        # í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´
        portfolio_info = ""
        portfolio_symbols = set()
        if portfolio:
            portfolio_info = "ë³´ìœ  ì¢…ëª©:\n"
            for stock in portfolio:
                portfolio_info += (
                    f"- {stock[1]}({stock[0]}): {stock[2]}ì£¼ (í‰ê·  {stock[3]:,}ì›)\n"
                )
                portfolio_symbols.add(stock[0])

        # ì‚¬ìš©ì íˆ¬ì ì •ë³´ ì¶”ê°€
        investment_profile = ""
        if user_info.get('investment_experience'):
            investment_profile += f"íˆ¬ì ê²½í—˜: {user_info['investment_experience']}\n"
        if user_info.get('investment_amount_range'):
            investment_profile += f"íˆ¬ì ê·œëª¨: {user_info['investment_amount_range']}\n"
        if user_info.get('investment_goals'):
            investment_profile += f"íˆ¬ì ëª©í‘œ: {', '.join(user_info['investment_goals'])}\n"

        # ì‚¬ìš©ì ë§ì¶¤ ê³µì‹œ ì •ë³´ ë¶„ì„
        disclosure_analysis = self._analyze_disclosure_for_portfolio(
            financial_data.get("disclosures", []), portfolio_symbols
        )

        # ê³µì‹œ-ë‰´ìŠ¤ ì—°ê´€ì„± ë¶„ì„
        cross_analysis = self._analyze_disclosure_news_correlation(
            financial_data.get("disclosures", []), financial_data.get("news", [])
        )

        preferred_sectors = preferences.get("preferred_sectors", "").split(",")
        sector_info = (
            f"ê´€ì‹¬ ì„¹í„°: {', '.join(preferred_sectors)}" if preferred_sectors else ""
        )
        investment_style = preferences.get("investment_style", "ê· í˜•í˜•")
        risk_level = preferences.get("risk_level", "ì¤‘ìœ„í—˜")

        # ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° í¬í•¨
        recent_news = ""
        if financial_data.get("news"):
            recent_news = "ìµœì‹  ë‰´ìŠ¤ í—¤ë“œë¼ì¸:\n"
            for i, news in enumerate(financial_data.get("news", [])[:5], 1):
                recent_news += f"{i}. {news.title}\n"

        # ì‹¤ì œ ì£¼ì‹ ë°ì´í„° í¬í•¨
        stock_performance = ""
        if financial_data.get("stock_data"):
            stock_performance = "ì£¼ìš” ì¢…ëª© í˜„í™©:\n"
            for stock in financial_data.get("stock_data", [])[:3]:
                change_sign = "+" if stock.change_percent > 0 else ""
                stock_performance += f"- {stock.symbol}: {stock.price:,}ì› ({change_sign}{stock.change_percent:.2f}%)\n"

        # HyperCLOVA Xì— ìµœì í™”ëœ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ê¸ˆìœµì‹œì¥ì˜ ìµœê³  ì „ë¬¸ê°€ì´ë©°, ê°œì¸ íˆ¬ììë¥¼ ìœ„í•œ í”„ë¦¬ë¯¸ì—„ íˆ¬ì ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤.
ì‹¤ì œ ì‹œì¥ ë°ì´í„°ì™€ ê³µì‹œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¹Šì´ ìˆê³  ì‹¤ìš©ì ì¸ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

=== í˜„ì¬ ì‹œì¥ ìƒí™© ===
{stock_performance}

=== ìµœì‹  ì‹œì¥ ë‰´ìŠ¤ ===
{recent_news}

=== ì‹œì¥ ë¶„ì„ ì •ë³´ (Graph RAG) ===
{graph_context}

=== íˆ¬ìì ìƒì„¸ í”„ë¡œí•„ ===
{investment_profile}
{portfolio_info}
{sector_info}
íˆ¬ì ìŠ¤íƒ€ì¼: {investment_style}
ìœ„í—˜ ìˆ˜ì¤€: {risk_level}

=== ê³µì‹œ ì •ë³´ ë¶„ì„ ===
{disclosure_analysis}

=== ê³µì‹œ-ë‰´ìŠ¤ ì—°ê´€ì„± ë¶„ì„ ===
{cross_analysis}

=== ê³ í’ˆì§ˆ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ì‘ì„± ìš”êµ¬ì‚¬í•­ ===

**í†¤ ì•¤ ë§¤ë„ˆ:**
- ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ íˆ¬ì ì „ë¬¸ê°€ì˜ ì–´ì¡°
- í™•ì‹ ì— ì°¬ ë¶„ì„ì´ì§€ë§Œ ë¦¬ìŠ¤í¬ì— ëŒ€í•œ ê· í˜•ì¡íŒ ì‹œê° ìœ ì§€
- ì¼ë°˜ì ì¸ ë‰´ìŠ¤ê°€ ì•„ë‹Œ 'ì¸ì‚¬ì´ë” ì •ë³´'ë¥¼ ì œê³µí•˜ëŠ” ëŠë‚Œ

**ë‚´ìš© êµ¬ì„±:**
1. **ì˜¤í”„ë‹**: í˜„ì¬ ì‹œì¥ ìƒí™©ì— ëŒ€í•œ í•µì‹¬ ì§„ë‹¨ (30ì´ˆ ë¶„ëŸ‰)
2. **í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„**: ë³´ìœ  ì¢…ëª©ë³„ êµ¬ì²´ì  ë¶„ì„ê³¼ ì „ë§ (60ì´ˆ ë¶„ëŸ‰)
3. **ì‹œì¥ ê¸°íšŒ**: ë†“ì¹˜ê¸° ì‰¬ìš´ íˆ¬ì ê¸°íšŒë‚˜ ì£¼ì˜ì  ì œì‹œ (45ì´ˆ ë¶„ëŸ‰)
4. **ì•¡ì…˜ ì•„ì´í…œ**: êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ íˆ¬ì ì¡°ì¹˜ ì œì•ˆ (30ì´ˆ ë¶„ëŸ‰)
5. **ë§ˆë¬´ë¦¬**: ë‹¤ìŒ ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸ ì•ˆë‚´ (15ì´ˆ ë¶„ëŸ‰)

**ê°œì¸í™” ìš”ì†Œ:**
- íˆ¬ììì˜ ê²½í—˜ ìˆ˜ì¤€({user_info.get('investment_experience', 'ì¤‘ê¸‰ì')})ì— ë§ëŠ” ì„¤ëª… ê¹Šì´ ì¡°ì ˆ
- ìœ„í—˜ ì„±í–¥({risk_level})ì„ ê³ ë ¤í•œ íˆ¬ì ì œì•ˆ
- íˆ¬ì ëª©í‘œ({', '.join(user_info.get('investment_goals', []))})ì— ë¶€í•©í•˜ëŠ” ì „ëµ ì œì‹œ

**ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ìš”ì†Œ:**
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° (ì£¼ê°€, ìˆ˜ìµë¥ , ê±°ë˜ëŸ‰ ë“±)
- ì‹œì¥ ìƒí™©ì— ëŒ€í•œ ëª…í™•í•œ íŒë‹¨ ("ê°•ì„¸", "ì•½ì„¸", "íš¡ë³´" ë“±)
- ë³´ìœ  ì¢…ëª©ì— ëŒ€í•œ ê°œë³„ì  ë¶„ì„
- ë‹¨ê¸°(1-3ê°œì›”)ì™€ ì¤‘ê¸°(6ê°œì›”-1ë…„) ì „ë§ êµ¬ë¶„
- ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ ëŒ€ì‘ ë°©ì•ˆ

**ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ:**
- ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ë»”í•œ ë‚´ìš©
- ì• ë§¤ëª¨í˜¸í•œ í‘œí˜„ ("ì¢‹ì„ ê²ƒ ê°™ë‹¤", "ë‚˜ì˜ì§€ ì•Šë‹¤" ë“±)
- ë‹¨ìˆœí•œ ë‰´ìŠ¤ ìš”ì•½
- ì±…ì„ íšŒí”¼ì„± ë¬¸êµ¬ ê³¼ë‹¤ ì‚¬ìš©

**ëª©í‘œ ë¶„ëŸ‰**: 1200-1500ì (ì•½ 3-4ë¶„ ì½ê¸° ë¶„ëŸ‰)
**ìŠ¤íƒ€ì¼**: í”„ë¦¬ë¯¸ì—„ ìì‚°ê´€ë¦¬ì‚¬ì˜ ê°œì¸ ë¸Œë¦¬í•‘ ëŠë‚Œ

í˜„ì¬ ì‹œì¥ ë°ì´í„°ì™€ íˆ¬ììì˜ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íˆ¬ììê°€ "ì´ëŸ° ë¶„ì„ì€ ì–´ë””ì„œë„ ë“¤ì„ ìˆ˜ ì—†ì—ˆë‹¤"ê³  ê°íƒ„í•  ë§Œí•œ ê³ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        return prompt

    def _analyze_disclosure_for_portfolio(
        self, disclosures: List, portfolio_symbols: set
    ) -> str:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© ê´€ë ¨ ê³µì‹œ ë¶„ì„"""
        if not disclosures or not portfolio_symbols:
            return "í˜„ì¬ ë³´ìœ  ì¢…ëª©ê³¼ ê´€ë ¨ëœ ìµœì‹  ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤."

        relevant_disclosures = []

        # ì¢…ëª© ì½”ë“œì™€ íšŒì‚¬ëª… ë§¤í•‘
        symbol_to_name = {
            "005930": "ì‚¼ì„±ì „ì",
            "000660": "SKí•˜ì´ë‹‰ìŠ¤",
            "035420": "NAVER",
            "005380": "í˜„ëŒ€ì°¨",
            "051910": "LGí™”í•™",
            "035720": "ì¹´ì¹´ì˜¤",
            "005490": "POSCOí™€ë”©ìŠ¤",
            "207940": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤",
            "068270": "ì…€íŠ¸ë¦¬ì˜¨",
        }

        portfolio_company_names = set()
        for symbol in portfolio_symbols:
            if symbol in symbol_to_name:
                portfolio_company_names.add(symbol_to_name[symbol])

        # ë³´ìœ  ì¢…ëª© ê´€ë ¨ ê³µì‹œ í•„í„°ë§
        for disclosure in disclosures:
            company_name = disclosure.company
            for portfolio_company in portfolio_company_names:
                if portfolio_company in company_name:
                    relevant_disclosures.append(
                        {
                            "company": company_name,
                            "title": disclosure.title,
                            "date": disclosure.date,
                            "importance": disclosure.importance_score,
                        }
                    )

        if not relevant_disclosures:
            return "ë³´ìœ  ì¢…ëª©ë“¤ì˜ ìµœê·¼ ê³µì‹œëŠ” ëŒ€ë¶€ë¶„ ì •ê¸° ë³´ê³ ì„œë¡œ, íŠ¹ë³„í•œ ë³€í™”ëŠ” ì—†ì–´ ë³´ì…ë‹ˆë‹¤. ì•ˆì •ì ì¸ ê²½ì˜ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."

        analysis = ">> ë³´ìœ  ì¢…ëª© ê³µì‹œ ë¶„ì„:\n"
        for disclosure in relevant_disclosures[:5]:
            analysis += f"- {disclosure['company']}: {disclosure['title']} ({disclosure['date']})\n"

            title_lower = disclosure["title"].lower()
            if "ë¶„ê¸°ë³´ê³ ì„œ" in title_lower:
                analysis += "  > ì‹¤ì  ë°œí‘œ ì˜ˆì •, ì£¼ê°€ ë³€ë™ì„± ì˜ˆìƒ\n"
            elif "ì‚¬ì—…ë³´ê³ ì„œ" in title_lower:
                analysis += "  > ì—°ê°„ ì „ëµ ë° ì‚¬ì—… ê³„íš ê³µê°œ, ì¥ê¸° íˆ¬ì ê´€ì ì—ì„œ ì¤‘ìš”\n"
            elif "ì£¼ì£¼ì´íšŒ" in title_lower:
                analysis += "  > ë°°ë‹¹ ì •ì±… ë° ê²½ì˜ì§„ ë³€í™” ê°€ëŠ¥ì„± ì£¼ëª©\n"
            elif "í•©ë³‘" in title_lower or "ì¸ìˆ˜" in title_lower:
                analysis += "  > ê¸°ì—… êµ¬ì¡° ë³€í™”, ê³ ìœ„í—˜-ê³ ìˆ˜ìµ ìƒí™©\n"
            else:
                analysis += "  > ì¶”ê°€ ëª¨ë‹ˆí„°ë§ í•„ìš”\n"

        return analysis

    def _analyze_disclosure_news_correlation(
        self, disclosures: List, news: List
    ) -> str:
        """ê³µì‹œì™€ ë‰´ìŠ¤ì˜ ì—°ê´€ì„± ë¶„ì„"""
        if not disclosures or not news:
            return "ê³µì‹œì™€ ë‰´ìŠ¤ ê°„ íŠ¹ë³„í•œ ì—°ê´€ì„±ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        correlations = []

        for disclosure in disclosures[:10]:
            disclosure_keywords = set(disclosure.title.split())
            disclosure_company = disclosure.company

            for news_item in news[:10]:
                news_title = news_item.title
                news_keywords = set(news_title.split())

                if disclosure_company in news_title:
                    correlations.append(
                        {
                            "type": "ê¸°ì—…ëª… ë§¤ì¹­",
                            "company": disclosure_company,
                            "disclosure": disclosure.title,
                            "news": news_title,
                            "correlation_strength": "ë†’ìŒ",
                        }
                    )

                common_keywords = disclosure_keywords.intersection(news_keywords)
                if len(common_keywords) >= 2:
                    correlations.append(
                        {
                            "type": "í‚¤ì›Œë“œ ì—°ê´€",
                            "company": disclosure_company,
                            "disclosure": disclosure.title,
                            "news": news_title,
                            "keywords": list(common_keywords),
                            "correlation_strength": "ì¤‘ê°„",
                        }
                    )

        if not correlations:
            return "í˜„ì¬ ê³µì‹œ ì •ë³´ì™€ ë‰´ìŠ¤ ì‚¬ì´ì— ì§ì ‘ì ì¸ ì—°ê´€ì„±ì€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ì´ëŠ” ì‹œì¥ì´ ì•„ì§ ê³µì‹œ ë‚´ìš©ì„ ì™„ì „íˆ ë°˜ì˜í•˜ì§€ ëª»í–ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."

        analysis = ">> ê³µì‹œ-ë‰´ìŠ¤ êµì°¨ ë¶„ì„:\n"
        for corr in correlations[:3]:
            analysis += f"- {corr['company']}: ê³µì‹œì™€ ë‰´ìŠ¤ê°€ ë™ì‹œ ë¶€ê°\n"
            analysis += f"  ê³µì‹œ: {corr['disclosure'][:50]}...\n"
            analysis += f"  ë‰´ìŠ¤: {corr['news'][:50]}...\n"
            analysis += f"  > ì‹œì¥ ê´€ì‹¬ë„ê°€ ë†’ì€ ìƒí™©, ì£¼ê°€ ë³€ë™ì„± í™•ëŒ€ ê°€ëŠ¥ì„±\n"

        return analysis

    def generate_personalized_insight(
        self, financial_data: Dict, user_id: str
    ) -> Optional[Dict]:
        """ê°œì¸í™”ëœ ì¸ì‚¬ì´íŠ¸ ìƒì„± (HyperCLOVA X ì‚¬ìš©)"""
        print(f">> ì‚¬ìš©ì {user_id}ë¥¼ ìœ„í•œ ê³ ê¸‰ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘")
        # RDBì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°
        user_profile = self.get_user_profile_from_db(user_id)

        if not self.llm_client.is_available():
            print(">> ì‚¬ìš© ê°€ëŠ¥í•œ LLM APIê°€ ì—†ìŒ. Mock ì¸ì‚¬ì´íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            result = self.generate_mock_personalized_insight(
                financial_data, user_profile
            )
            result["analysis_method"] = "Mock ë°ì´í„° (LLM API ì—†ìŒ) + Graph RAG + DART"
            result["model_used"] = "Mock (LLM ë¯¸ì‚¬ìš©)"
            return result

        try:
            prompt = self.create_personalized_script_prompt(
                financial_data, user_profile
            )

            provider = self.llm_client.get_current_provider()
            print(f">> {provider} APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")

            response = self.llm_client.chat_completion(
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ì˜ ê¸°ì—… ê³µì‹œ ì •ë³´ì™€ ì‹œì¥ ë‰´ìŠ¤ë¥¼ ì¢…í•© ë¶„ì„í•˜ëŠ” ì „ë¬¸ íˆ¬ì ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤. í•œêµ­ íˆ¬ììì˜ ì •ì„œì™€ ì‹œì¥ íŠ¹ì„±ì„ ê¹Šì´ ì´í•´í•˜ê³ , ì¼ë°˜ì¸ì´ ì ‘í•˜ê¸° ì–´ë ¤ìš´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°¨ë³„í™”ëœ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•©ë‹ˆë‹¤.",
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=3000,
                temperature=0.7,
            )

            if not response:
                print(f">> {provider} API ì‘ë‹µ ì—†ìŒ, Mock ì¸ì‚¬ì´íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
                result = self.generate_mock_personalized_insight(
                    financial_data, user_profile
                )
                result["analysis_method"] = (
                    f"Mock ë°ì´í„° ({provider} API ì‹¤íŒ¨) + Graph RAG + DART"
                )
                result["model_used"] = f"Mock (ì›ë˜ {provider} ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨)"
                return result

            # HyperCLOVA X ì‘ë‹µ ì²˜ë¦¬ (OpenAI í˜•ì‹ ì•„ë‹˜)
            script_content = response.get_content().strip()

            return {
                "script": script_content,
                "user_id": user_id,
                "analysis_method": f"ì‹¤ì œ {provider} API + Graph RAG + DART Disclosures + RDB Profile",
                "portfolio_analysis": self._analyze_portfolio_performance(
                    user_profile, financial_data
                ),
                "personalized_news": self._filter_personalized_news(
                    financial_data, user_profile
                ),
                "disclosure_insights": self._analyze_disclosure_for_portfolio(
                    financial_data.get("disclosures", []),
                    set(holding[0] for holding in user_profile.get("portfolio", [])),
                ),
                "graph_analysis": self.graph_rag.create_market_narrative(
                    financial_data
                ),
                "token_usage": response.get_usage()["total_tokens"],
                "model_used": f"ì‹¤ì œ {provider} API",
                "data_sources": {
                    "news_count": len(financial_data.get("news", [])),
                    "disclosure_count": len(financial_data.get("disclosures", [])),
                    "stock_count": len(financial_data.get("stock_data", [])),
                },
                "user_profile_source": "RDB"
            }
        except Exception as e:
            print(f">> ê³ ê¸‰ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}, Mock ì¸ì‚¬ì´íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            result = self.generate_mock_personalized_insight(
                financial_data, user_profile
            )
            result["analysis_method"] = (
                f"Mock ë°ì´í„° (ì˜ˆì™¸ ë°œìƒ: {str(e)[:50]}) + Graph RAG + DART + RDB Profile"
            )
            result["model_used"] = "Mock (ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì¸í•œ ëŒ€ì²´)"
            return result

    def _analyze_portfolio_performance(
        self, user_profile: Dict, financial_data: Dict
    ) -> Dict:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¶„ì„ (ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©)"""
        portfolio = user_profile.get("portfolio", [])
        if not portfolio:
            return {
                "total_value": 0,
                "total_cost": 0,
                "total_return": 0,
                "total_return_percent": 0.0,
                "holdings_count": 0,
                "best_performer": None,
                "worst_performer": None,
                "error": "í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
            }

        stock_data_map = {}
        for stock in financial_data.get("stock_data", []):
            stock_data_map[stock.symbol] = stock

        total_value = 0
        total_cost = 0
        holdings_analysis = []
        missing_data_count = 0

        print(f">> í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„: {len(portfolio)}ê°œ ë³´ìœ  ì¢…ëª©")

        for holding in portfolio:
            symbol, company_name, shares, avg_price = (
                holding[0],
                holding[1],
                holding[2],
                holding[3],
            )

            print(
                f">> ë¶„ì„ ì¤‘: {company_name}({symbol}) - {shares}ì£¼, í‰ê·  {avg_price:,}ì›"
            )

            current_price = None
            data_source = "ì‹¤ì œ ë°ì´í„° ì—†ìŒ"

            if symbol in stock_data_map:
                stock_info = stock_data_map[symbol]
                if stock_info.price > 0:
                    current_price = stock_info.price
                    data_source = "ì‹¤ì‹œê°„ ë°ì´í„°"
                    print(f"   >> ì‹¤ì œ í˜„ì¬ê°€: {current_price:,}ì›")
                else:
                    print(
                        f"   >> ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ (ê°€ê²©: {stock_info.price})"
                    )
                    missing_data_count += 1
            else:
                print(f"   >> ì‹¤ì‹œê°„ ë°ì´í„° ì—†ìŒ")
                missing_data_count += 1

            if current_price is None:
                holdings_analysis.append(
                    {
                        "symbol": symbol,
                        "company_name": company_name,
                        "shares": shares,
                        "avg_price": avg_price,
                        "current_price": None,
                        "cost": avg_price * shares,
                        "value": None,
                        "return": None,
                        "return_percent": None,
                        "data_source": data_source,
                        "error": "ì‹¤ì‹œê°„ ë°ì´í„° ì—†ìŒ",
                    }
                )
                continue

            holding_cost = avg_price * shares
            holding_value = current_price * shares
            holding_return = holding_value - holding_cost
            holding_return_percent = (
                (holding_return / holding_cost) * 100 if holding_cost > 0 else 0
            )

            holdings_analysis.append(
                {
                    "symbol": symbol,
                    "company_name": company_name,
                    "shares": shares,
                    "avg_price": avg_price,
                    "current_price": current_price,
                    "cost": holding_cost,
                    "value": holding_value,
                    "return": holding_return,
                    "return_percent": holding_return_percent,
                    "data_source": data_source,
                }
            )

            total_cost += holding_cost
            total_value += holding_value

            print(f"   >> ìˆ˜ìµ: {holding_return:+,}ì› ({holding_return_percent:+.2f}%)")

        total_return = total_value - total_cost
        total_return_percent = (
            (total_return / total_cost) * 100 if total_cost > 0 else 0
        )

        valid_holdings = [
            h for h in holdings_analysis if h.get("return_percent") is not None
        ]
        best_performer = (
            max(valid_holdings, key=lambda x: x["return_percent"])
            if valid_holdings
            else None
        )
        worst_performer = (
            min(valid_holdings, key=lambda x: x["return_percent"])
            if valid_holdings
            else None
        )

        data_quality_warning = None
        if missing_data_count > 0:
            data_quality_warning = f"{missing_data_count}ê°œ ì¢…ëª©ì˜ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ì„œ ë¶„ì„ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤."

        result = {
            "total_value": total_value,
            "total_cost": total_cost,
            "total_return": total_return,
            "total_return_percent": total_return_percent,
            "holdings_count": len(portfolio),
            "analyzed_holdings_count": len(valid_holdings),
            "missing_data_count": missing_data_count,
            "best_performer": best_performer,
            "worst_performer": worst_performer,
            "holdings_detail": holdings_analysis,
            "data_quality_warning": data_quality_warning,
        }

        print(f">> í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì´ ë³´ìœ  ì¢…ëª©: {len(portfolio)}ê°œ")
        print(f"   ë¶„ì„ ê°€ëŠ¥ ì¢…ëª©: {len(valid_holdings)}ê°œ")
        if missing_data_count > 0:
            print(f"   >> ë°ì´í„° ì—†ëŠ” ì¢…ëª©: {missing_data_count}ê°œ")
        if valid_holdings:
            print(f"   íˆ¬ìê¸ˆ: {total_cost:,}ì›")
            print(f"   í‰ê°€ì•¡: {total_value:,}ì›")
            print(f"   ìˆ˜ìµ: {total_return:+,}ì› ({total_return_percent:+.2f}%)")
        else:
            print(
                f"   >> ëª¨ë“  ì¢…ëª©ì˜ ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì—†ì–´ì„œ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        return result

    def _filter_personalized_news(
        self, financial_data: Dict, user_profile: Dict
    ) -> List[Dict]:
        """ê°œì¸í™”ëœ ë‰´ìŠ¤ í•„í„°ë§ (ê³µì‹œ ì—°ê´€ì„± í¬í•¨)"""
        news_items = financial_data.get("news", [])
        disclosures = financial_data.get("disclosures", [])

        enhanced_news = []

        for news in news_items:
            relevance_score = news.importance_score

            # ê³µì‹œì™€ ì—°ê´€ì„± ì²´í¬
            for disclosure in disclosures:
                if disclosure.company in news.title:
                    relevance_score += 1.0

            enhanced_news.append(
                {
                    "title": news.title,
                    "summary": news.summary,
                    "entities": news.entities,
                    "importance_score": news.importance_score,
                    "relevance_score": relevance_score,
                    "has_disclosure_link": any(
                        d.company in news.title for d in disclosures
                    ),
                }
            )

        enhanced_news.sort(key=lambda x: x["relevance_score"], reverse=True)
        return enhanced_news[:5]

    def generate_mock_personalized_insight(
        self, financial_data: Dict, user_profile: Dict
    ) -> Dict:
        """Mock ê°œì¸í™” ì¸ì‚¬ì´íŠ¸ ìƒì„± (HyperCLOVA X ìŠ¤íƒ€ì¼ - ê°œì„ ëœ ë²„ì „)"""
        portfolio_analysis = self._analyze_portfolio_performance(
            user_profile, financial_data
        )
        graph_analysis = self.graph_rag.create_market_narrative(financial_data)

        top_entity_info = "ë¶„ì„ëœ í•µì‹¬ ì—”í‹°í‹°ê°€ ì—†ìŠµë‹ˆë‹¤."
        if graph_analysis and graph_analysis.get("market_summary", {}).get(
            "top_entities"
        ):
            top_entity = graph_analysis["market_summary"]["top_entities"][0]
            top_entity_info = f"{top_entity[0]}ì´(ê°€) ê°€ì¥ ì£¼ëª©ë°›ëŠ” í•µì‹¬ ìš”ì†Œë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤ (ì¤‘ìš”ë„: {top_entity[1]}ì )."

        # ì‹¤ì œ ì£¼ì‹ ë°ì´í„° ê¸°ë°˜ ë¶„ì„
        market_analysis = ""
        if financial_data.get("stock_data"):
            positive_stocks = []
            negative_stocks = []
            for stock in financial_data.get("stock_data", []):
                if stock.change_percent > 0:
                    positive_stocks.append(
                        f"{stock.symbol}(+{stock.change_percent:.1f}%)"
                    )
                else:
                    negative_stocks.append(
                        f"{stock.symbol}({stock.change_percent:.1f}%)"
                    )

            if positive_stocks:
                market_analysis += f"ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ëŠ” {', '.join(positive_stocks[:2])} ë“±ì´ ì‹œì¥ì„ ê²¬ì¸í•˜ê³  ìˆìœ¼ë©°, "
            if negative_stocks:
                market_analysis += (
                    f"{', '.join(negative_stocks[:2])} ë“±ì€ ì¡°ì • ì••ë ¥ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤."
                )

        # í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ê¸°ë°˜ ê°œì¸í™” ë©”ì‹œì§€
        portfolio_message = ""
        if portfolio_analysis.get("total_return_percent", 0) > 0:
            portfolio_message = f"ê·€í•˜ì˜ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” í˜„ì¬ {portfolio_analysis.get('total_return_percent', 0):.2f}%ì˜ ì–‘í˜¸í•œ ìˆ˜ìµë¥ ì„ ê¸°ë¡í•˜ê³  ìˆì–´ ì‹œì¥ ëŒ€ë¹„ ì„ ë°©í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        elif portfolio_analysis.get("total_return_percent", 0) < -5:
            portfolio_message = f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ ì´ {portfolio_analysis.get('total_return_percent', 0):.2f}%ë¡œ ë‹¤ì†Œ ë¶€ì§„í•œ ìƒí™©ì´ì§€ë§Œ, í˜„ì¬ ì‹œì¥ ì¡°ì •ê¸°ë¥¼ ê°ì•ˆí•  ë•Œ ì¤‘ì¥ê¸° ê´€ì ì—ì„œ ì ‘ê·¼í•˜ì‹œê¸¸ ê¶Œí•©ë‹ˆë‹¤."
        else:
            portfolio_message = f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  {portfolio_analysis.get('total_return_percent', 0):.2f}%ë¡œ ì‹œì¥ê³¼ ë¹„ìŠ·í•œ ì›€ì§ì„ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."

        # HyperCLOVA X ìŠ¤íƒ€ì¼ì˜ ê³ í’ˆì§ˆ í•œêµ­ì–´ Mock ì¸ì‚¬ì´íŠ¸
        script = f"""
ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì˜ ë§ì¶¤í˜• íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì „í•´ë“œë¦½ë‹ˆë‹¤.

í˜„ì¬ ì‹œì¥ì€ í˜¼ì¡°ì„¸ ì†ì—ì„œë„ êµ¬ì¡°ì  ë³€í™”ì˜ ì‹ í˜¸ë¥¼ ë³´ë‚´ê³  ìˆìŠµë‹ˆë‹¤. {market_analysis} {top_entity_info}

{portfolio_message}

íŠ¹íˆ ì£¼ëª©í•  ì ì€ AIì™€ ë°˜ë„ì²´ ì„¹í„°ì˜ í€ë”ë©˜í„¸ ê°œì„ ì…ë‹ˆë‹¤. ë„¤ì´ë²„ì˜ í•˜ì´í¼í´ë¡œë°”X ìƒìš©í™”ê°€ ë³¸ê²©í™”ë˜ë©´ì„œ ê´€ë ¨ ìƒíƒœê³„ ê¸°ì—…ë“¤ì˜ ìˆ˜í˜œê°€ ì˜ˆìƒë˜ê³ , ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ì˜ HBM ì‹œì¥ ì„ ì  ê²½ìŸì´ ì¹˜ì—´í•´ì§€ê³  ìˆì–´ ë©”ëª¨ë¦¬ ì—…ê³„ì˜ ì¬í‰ê°€ êµ­ë©´ì´ ì§€ì†ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

ë‹¨ê¸°ì ìœ¼ë¡œëŠ” ë¯¸êµ­ ì—°ì¤€ì˜ í†µí™”ì •ì±… ë°©í–¥ì„±ê³¼ ì¤‘êµ­ ê²½ì œ íšŒë³µ ì†ë„ê°€ ë³€ìˆ˜ê°€ ë  ê²ƒì´ë©°, íŠ¹íˆ 2ë¶„ê¸° ì‹¤ì  ì‹œì¦Œì„ ì•ë‘ê³  ê°œë³„ ê¸°ì—…ì˜ ê°€ì´ë˜ìŠ¤ì— ì£¼ëª©í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.

ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì°¨ì›ì—ì„œ í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆê³¼ ë¶„ì‚°íˆ¬ì ì›ì¹™ì„ ê²¬ì§€í•˜ì‹œë˜, ì¥ê¸° ì„±ì¥ ë™ë ¥ì´ í™•ì‹¤í•œ ê¸°ìˆ ì£¼ ë¹„ì¤‘ì€ ìœ ì§€í•˜ì‹œê¸¸ ê¶Œí•©ë‹ˆë‹¤.

ë‹¤ìŒ ì£¼ ì£¼ìš” ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸ë¡œëŠ” í•œêµ­ì€í–‰ ê¸ˆí†µìœ„ ê²°ê³¼ì™€ ì£¼ìš” ê¸°ì—…ë“¤ì˜ 1ë¶„ê¸° ì‹¤ì  ë°œí‘œê°€ ìˆê² ìŠµë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
"""

        return {
            "script": script.strip(),
            "user_id": "mock_user",
            "analysis_method": "Mock HyperCLOVA-X + Graph RAG + DART + Real Market Data",
            "portfolio_analysis": portfolio_analysis,
            "personalized_news": [],
            "investment_opportunities": [],
            "graph_analysis": graph_analysis,
            "model_used": "Mock-HyperCLOVA-X",
        }

    def save_user_portfolio(self, user_id: str, portfolio_data: List[Dict]):
        """ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ì €ì¥"""
        conn = sqlite3.connect(self.data_collector.db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM user_portfolios WHERE user_id = ?", (user_id,))
        cursor.executemany(
            "INSERT INTO user_portfolios (user_id, symbol, company_name, shares, avg_price, sector) VALUES (?, ?, ?, ?, ?, ?)",
            [
                (
                    user_id,
                    h["symbol"],
                    h["company_name"],
                    h["shares"],
                    h["avg_price"],
                    h.get("sector"),
                )
                for h in portfolio_data
            ],
        )
        conn.commit()
        conn.close()

    def save_user_preferences(self, user_id: str, preferences: Dict):
        """ì‚¬ìš©ì íˆ¬ì ì„ í˜¸ë„ ì €ì¥"""
        conn = sqlite3.connect(self.data_collector.db_path)
        cursor = conn.cursor()
        cursor.execute(
            "INSERT OR REPLACE INTO user_preferences (user_id, preferred_sectors, risk_level, investment_style, news_keywords) VALUES (?, ?, ?, ?, ?)",
            (
                user_id,
                ",".join(preferences.get("preferred_sectors", [])),
                preferences.get("risk_level", "ì¤‘ìœ„í—˜"),
                preferences.get("investment_style", "ê· í˜•í˜•"),
                ",".join(preferences.get("news_keywords", [])),
            ),
        )
        conn.commit()
        conn.close()

    # === í•µì‹¬ ìˆ˜ì •: ë©”ì„œë“œëª… ë³€ê²½ìœ¼ë¡œ ì¤‘ë³µ í•´ê²° ===

    async def generate_comprehensive_insight_async(
        self, user_id: str, refresh_data: bool = False
    ) -> Dict:
        """ë¹„ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± (FastAPIìš©) - ë©”ì„œë“œëª… ë³€ê²½"""
        print(f">> ì‚¬ìš©ì {user_id}ë¥¼ ìœ„í•œ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘ (ë¹„ë™ê¸°)")

        try:
            # ë°ì´í„° ìˆ˜ì§‘ (ë¹„ë™ê¸° ë²„ì „ ì‚¬ìš©)
            financial_data = await self.data_collector.collect_all_data_async(
                user_id=user_id, refresh_cache=refresh_data, use_playwright=True
            )

            # ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸ ìƒì„± ë¡œì§ ì¬ì‚¬ìš©
            comprehensive_script = self._generate_comprehensive_script(
                financial_data=financial_data, user_id=user_id
            )

            # ë‚˜ë¨¸ì§€ ë¶„ì„ë“¤
            user_profile = financial_data.get("personalized", {})

            portfolio_analysis = self._analyze_portfolio_performance(
                user_profile, financial_data
            )

            personalized_news = self._filter_personalized_news(
                financial_data, user_profile
            )

            disclosure_insights = self._analyze_disclosure_for_portfolio(
                financial_data.get("disclosures", []),
                set(holding[0] for holding in user_profile.get("portfolio", [])),
            )

            graph_analysis = self.graph_rag.create_market_narrative(financial_data)

            # ê²°ê³¼ ë°˜í™˜
            result = {
                "script": comprehensive_script,
                "script_length": len(comprehensive_script),
                "estimated_reading_time": f"ì•½ {max(1, len(comprehensive_script) // 200)}ë¶„",
                "analysis_method": "Graph RAG + ì‹¤ì‹œê°„ ë°ì´í„° + ê°œì¸í™” ë¶„ì„ (ë¹„ë™ê¸°)",
                "portfolio_analysis": portfolio_analysis,
                "personalized_news": personalized_news,
                "disclosure_insights": disclosure_insights,
                "graph_analysis": graph_analysis,
                "token_usage": getattr(self, "_last_token_usage", 0),
                "model_used": getattr(self, "_current_model", "HyperCLOVA-X"),
                "data_sources": financial_data.get("data_sources", {}),
            }

            print(f">> ë¹„ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(comprehensive_script)}ì")
            return result

        except Exception as e:
            print(f">> ë¹„ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e

    def generate_comprehensive_insight(
        self, user_id: str, refresh_data: bool = False
    ) -> Dict:
        """ê¸°ì¡´ ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        print(f">> ì‚¬ìš©ì {user_id}ë¥¼ ìœ„í•œ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘ (ë™ê¸°)")

        try:
            # ë°ì´í„° ìˆ˜ì§‘ (ë™ê¸° ë²„ì „ ì‚¬ìš© - PlaywrightëŠ” ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
            financial_data = self.data_collector.collect_all_data(
                user_id=user_id, refresh_cache=refresh_data, use_playwright=True
            )

            # ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸ ìƒì„± ë¡œì§ ì¬ì‚¬ìš©
            comprehensive_script = self._generate_comprehensive_script(
                financial_data=financial_data, user_id=user_id
            )

            # ë‚˜ë¨¸ì§€ ë¶„ì„ë“¤
            user_profile = financial_data.get("personalized", {})

            portfolio_analysis = self._analyze_portfolio_performance(
                user_profile, financial_data
            )

            personalized_news = self._filter_personalized_news(
                financial_data, user_profile
            )

            disclosure_insights = self._analyze_disclosure_for_portfolio(
                financial_data.get("disclosures", []),
                set(holding[0] for holding in user_profile.get("portfolio", [])),
            )

            graph_analysis = self.graph_rag.create_market_narrative(financial_data)

            result = {
                "script": comprehensive_script,
                "script_length": len(comprehensive_script),
                "estimated_reading_time": f"ì•½ {max(1, len(comprehensive_script) // 200)}ë¶„",
                "analysis_method": "Graph RAG + ì‹¤ì‹œê°„ ë°ì´í„° + ê°œì¸í™” ë¶„ì„ (ë™ê¸°)",
                "portfolio_analysis": portfolio_analysis,
                "personalized_news": personalized_news,
                "disclosure_insights": disclosure_insights,
                "graph_analysis": graph_analysis,
                "token_usage": getattr(self, "_last_token_usage", 0),
                "model_used": getattr(self, "_current_model", "HyperCLOVA-X"),
                "data_sources": financial_data.get("data_sources", {}),
            }

            print(f">> ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(comprehensive_script)}ì")
            return result

        except Exception as e:
            print(f">> ë™ê¸° ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e

    def _generate_comprehensive_script(self, financial_data: Dict, user_id: str) -> str:
        """í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)"""
        # ê¸°ì¡´ generate_personalized_insight ë¡œì§ ì‚¬ìš©
        insight_result = self.generate_personalized_insight(financial_data, user_id)

        if insight_result and insight_result.get("script"):
            return insight_result["script"]
        else:
            # Mock ì¸ì‚¬ì´íŠ¸ë¡œ í´ë°±
            user_profile = self.data_collector.get_personalized_data(user_id)
            mock_result = self.generate_mock_personalized_insight(
                financial_data, user_profile
            )
            return mock_result.get("script", "ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
